"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[421],{5680:(e,t,n)=>{n.d(t,{xA:()=>c,yg:()=>g});var o=n(6540);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,o,r=function(e,t){if(null==e)return{};var n,o,r={},a=Object.keys(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var d=o.createContext({}),s=function(e){var t=o.useContext(d),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},c=function(e){var t=s(e.components);return o.createElement(d.Provider,{value:t},e.children)},p="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},m=o.forwardRef((function(e,t){var n=e.components,r=e.mdxType,a=e.originalType,d=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),p=s(n),m=r,g=p["".concat(d,".").concat(m)]||p[m]||u[m]||a;return n?o.createElement(g,i(i({ref:t},c),{},{components:n})):o.createElement(g,i({ref:t},c))}));function g(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var a=n.length,i=new Array(a);i[0]=m;var l={};for(var d in t)hasOwnProperty.call(t,d)&&(l[d]=t[d]);l.originalType=e,l[p]="string"==typeof e?e:r,i[1]=l;for(var s=2;s<a;s++)i[s]=n[s];return o.createElement.apply(null,i)}return o.createElement.apply(null,n)}m.displayName="MDXCreateElement"},1342:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>i,default:()=>u,frontMatter:()=>a,metadata:()=>l,toc:()=>s});var o=n(8168),r=(n(6540),n(5680));const a={title:"SpeechToTextModule",sidebar_position:6},i=void 0,l={unversionedId:"hookless-api/SpeechToTextModule",id:"hookless-api/SpeechToTextModule",title:"SpeechToTextModule",description:"Hookless implementation of the useSpeechToText hook.",source:"@site/docs/hookless-api/SpeechToTextModule.md",sourceDirName:"hookless-api",slug:"/hookless-api/SpeechToTextModule",permalink:"/react-native-executorch/docs/hookless-api/SpeechToTextModule",draft:!1,editUrl:"https://github.com/software-mansion/react-native-executorch/edit/main/docs/docs/hookless-api/SpeechToTextModule.md",tags:[],version:"current",sidebarPosition:6,frontMatter:{title:"SpeechToTextModule",sidebar_position:6},sidebar:"tutorialSidebar",previous:{title:"OCRModule",permalink:"/react-native-executorch/docs/hookless-api/OCRModule"},next:{title:"VerticalOCRModule",permalink:"/react-native-executorch/docs/hookless-api/VerticalOCRModule"}},d={},s=[{value:"Reference",id:"reference",level:2},{value:"Methods",id:"methods",level:3},{value:"Loading the model",id:"loading-the-model",level:2},{value:"Running the model",id:"running-the-model",level:2},{value:"Obtaining the input",id:"obtaining-the-input",level:2}],c={toc:s},p="wrapper";function u(e){let{components:t,...n}=e;return(0,r.yg)(p,(0,o.A)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,r.yg)("p",null,"Hookless implementation of the ",(0,r.yg)("a",{parentName:"p",href:"/react-native-executorch/docs/speech-to-text/useSpeechToText"},"useSpeechToText")," hook."),(0,r.yg)("h2",{id:"reference"},"Reference"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-typescript"},"import { SpeechToTextModule } from 'react-native-executorch';\n\nconst audioUrl = ...; // URL with audio to transcribe\n\n// Loading the model\nconst onSequenceUpdate = (sequence) => {\n    console.log(sequence);\n};\nawait SpeechToTextModule.load('moonshine', onSequenceUpdate);\n\n// Loading the audio and running the model\nawait SpeechToTextModule.loadAudio(audioUrl);\nconst transcribedText = await SpeechToTextModule.transcribe();\n")),(0,r.yg)("h3",{id:"methods"},"Methods"),(0,r.yg)("table",null,(0,r.yg)("thead",{parentName:"table"},(0,r.yg)("tr",{parentName:"thead"},(0,r.yg)("th",{parentName:"tr",align:null},"Method"),(0,r.yg)("th",{parentName:"tr",align:null},"Type"),(0,r.yg)("th",{parentName:"tr",align:null},"Description"))),(0,r.yg)("tbody",{parentName:"table"},(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"load")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("code",null,"(modelName: 'whisper' ","|"," 'moonshine, transcribeCallback?: (sequence: string) => void, modelDownloadProgressCalback?: (downloadProgress: number) => void, encoderSource?: ResourceSource, decoderSource?: ResourceSource, tokenizerSource?: ResourceSource)")),(0,r.yg)("td",{parentName:"tr",align:null},"Loads the model specified with ",(0,r.yg)("inlineCode",{parentName:"td"},"modelName"),", where ",(0,r.yg)("inlineCode",{parentName:"td"},"encoderSource"),", ",(0,r.yg)("inlineCode",{parentName:"td"},"decoderSource"),", ",(0,r.yg)("inlineCode",{parentName:"td"},"tokenizerSource")," are strings specifying the location of the binaries for the models. ",(0,r.yg)("inlineCode",{parentName:"td"},"modelDownloadProgressCallback")," allows you to monitor the current progress of the model download, while ",(0,r.yg)("inlineCode",{parentName:"td"},"transcribeCallback")," is invoked with each generated token")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"transcribe")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"(waveform: number[]): Promise<string>")),(0,r.yg)("td",{parentName:"tr",align:null},"Starts a transcription process for a given input array, which should be a waveform at 16kHz. When no input is provided, it uses an internal state which is set by calling ",(0,r.yg)("inlineCode",{parentName:"td"},"loadAudio"),". Resolves a promise with the output transcription when the model is finished.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"loadAudio")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"(url: string) => void")),(0,r.yg)("td",{parentName:"tr",align:null},"Loads audio file from given url. It sets an internal state which serves as an input to ",(0,r.yg)("inlineCode",{parentName:"td"},"transcribe()"),".")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"encode")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"(waveform: number[]) => Promise<number[]>")),(0,r.yg)("td",{parentName:"tr",align:null},"Runs the encoding part of the model. Returns a float array representing the output of the encoder.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"decode")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"(tokens: number[], encodings: number[]) => Promise<number[]>")),(0,r.yg)("td",{parentName:"tr",align:null},"Runs the decoder of the model. Returns a single token representing a next token in the output sequence.")))),(0,r.yg)("details",null,(0,r.yg)("summary",null,"Type definitions"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-typescript"},"type ResourceSource = string | number;\n"))),(0,r.yg)("h2",{id:"loading-the-model"},"Loading the model"),(0,r.yg)("p",null,"To load the model, use the ",(0,r.yg)("inlineCode",{parentName:"p"},"load")," method. The required argument is ",(0,r.yg)("inlineCode",{parentName:"p"},"modelName"),", which serves as an identifier for which model to use. It also accepts accepts optional arguments such as ",(0,r.yg)("inlineCode",{parentName:"p"},"encoderSource"),", ",(0,r.yg)("inlineCode",{parentName:"p"},"decoderSource"),", ",(0,r.yg)("inlineCode",{parentName:"p"},"tokenizerSource")," which are strings that specify the location of the binaries for the model. For more information, take a look at ",(0,r.yg)("a",{parentName:"p",href:"/react-native-executorch/docs/fundamentals/loading-models"},"loading models")," page. This method returns a promise, which can resolve to an error or void."),(0,r.yg)("h2",{id:"running-the-model"},"Running the model"),(0,r.yg)("p",null,"To run the model, you can use the ",(0,r.yg)("inlineCode",{parentName:"p"},"transcribe")," method. It accepts one argument, which is an array of numbers representing a waveform at 16kHz sampling rate. The method returns a promise, which can resolve either to an error or a string containing the output text."),(0,r.yg)("h2",{id:"obtaining-the-input"},"Obtaining the input"),(0,r.yg)("p",null,"To get the input, you can use the ",(0,r.yg)("inlineCode",{parentName:"p"},"loadAudio")," method, which sets the internal input state of the model. Then you can just call ",(0,r.yg)("inlineCode",{parentName:"p"},"transcribe")," without passing any args. It is also possible to pass inputs from other sources, as long as it is a float array containing the aforementioned waveform."))}u.isMDXComponent=!0}}]);