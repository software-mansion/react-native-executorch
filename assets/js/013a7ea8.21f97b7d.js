"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[4177],{7716:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>d,contentTitle:()=>c,default:()=>h,frontMatter:()=>s,metadata:()=>n,toc:()=>l});const n=JSON.parse('{"id":"typescript-api/TokenizerModule","title":"TokenizerModule","description":"TypeScript API implementation of the useTokenizer hook.","source":"@site/versioned_docs/version-0.4.x/typescript-api/TokenizerModule.md","sourceDirName":"typescript-api","slug":"/typescript-api/TokenizerModule","permalink":"/react-native-executorch/docs/0.4.x/typescript-api/TokenizerModule","draft":false,"unlisted":false,"editUrl":"https://github.com/software-mansion/react-native-executorch/edit/main/docs/versioned_docs/version-0.4.x/typescript-api/TokenizerModule.md","tags":[],"version":"0.4.x","frontMatter":{"title":"TokenizerModule"},"sidebar":"tutorialSidebar","previous":{"title":"TextEmbeddingsModule","permalink":"/react-native-executorch/docs/0.4.x/typescript-api/TextEmbeddingsModule"},"next":{"title":"Computer Vision","permalink":"/react-native-executorch/docs/0.4.x/category/computer-vision-1"}}');var r=o(4848),i=o(8453);const s={title:"TokenizerModule"},c=void 0,d={},l=[{value:"Reference",id:"reference",level:2},{value:"Methods",id:"methods",level:3}];function a(e){const t={a:"a",code:"code",h2:"h2",h3:"h3",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,i.R)(),...e.components},{Details:o}=t;return o||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(t.p,{children:["TypeScript API implementation of the ",(0,r.jsx)(t.a,{href:"/react-native-executorch/docs/0.4.x/natural-language-processing/useTokenizer",children:"useTokenizer"})," hook."]}),"\n",(0,r.jsx)(t.h2,{id:"reference",children:"Reference"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-typescript",children:"import {\n  TokenizerModule,\n  ALL_MINILM_L6_V2_TOKENIZER,\n} from 'react-native-executorch';\n\n// Load the tokenizer\nawait TokenizerModule.load(ALL_MINILM_L6_V2_TOKENIZER);\nconsole.log('Tokenizer loaded');\n\n// Get tokenizers vocabulary size\nconst vocabSize = await TokenizerModule.getVocabSize();\nconsole.log('Vocabulary size:', vocabSize);\n\nconst text = 'Hello, world!';\n\n// Tokenize the text\nconst tokens = await TokenizerModule.encode(text);\nconsole.log('Token IDs:', tokens);\n\n// Decode the tokens back to text\nconst decoded = await TokenizerModule.decode(tokens);\nconsole.log('Decoded text:', decoded);\n\n// Get the token ID for a specific token\nconst tokenId = await TokenizerModule.tokenToId('hello');\nconsole.log('Token ID for \"Hello\":', tokenId);\n\n// Get the token for a specific ID\nconst token = await TokenizerModule.idToToken(tokenId);\nconsole.log('Token for ID:', token);\n"})}),"\n",(0,r.jsx)(t.h3,{id:"methods",children:"Methods"}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Method"}),(0,r.jsx)(t.th,{children:"Type"}),(0,r.jsx)(t.th,{children:"Description"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"load"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"(tokenizerSource: ResourceSource): Promise<void>"})}),(0,r.jsxs)(t.td,{children:["Loads the tokenizer from the specified source. ",(0,r.jsx)(t.code,{children:"tokenizerSource"})," is a string that points to the location of the tokenizer JSON file."]})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"encode"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"(input: string): Promise<number[]>"})}),(0,r.jsx)(t.td,{children:"Converts a string into an array of token IDs."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"decode"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"(input: number[]): Promise<string>"})}),(0,r.jsx)(t.td,{children:"Converts an array of token IDs into a string."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"getVocabSize"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"(): Promise<number>"})}),(0,r.jsx)(t.td,{children:"Returns the size of the tokenizer's vocabulary."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"idToToken"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"(tokenId: number): Promise<string>"})}),(0,r.jsx)(t.td,{children:"Returns the token associated to the ID."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"tokenToId"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"(token: string): Promise<number>"})}),(0,r.jsx)(t.td,{children:"Returns the ID associated to the token."})]})]})]}),"\n",(0,r.jsxs)(o,{children:[(0,r.jsx)("summary",{children:"Type definitions"}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-typescript",children:"type ResourceSource = string | number | object;\n"})})]})]})}function h(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(a,{...e})}):a(e)}},8453:(e,t,o)=>{o.d(t,{R:()=>s,x:()=>c});var n=o(6540);const r={},i=n.createContext(r);function s(e){const t=n.useContext(i);return n.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function c(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),n.createElement(i.Provider,{value:t},e.children)}}}]);