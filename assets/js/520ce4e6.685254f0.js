"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[203],{5680:(e,t,n)=>{n.d(t,{xA:()=>d,yg:()=>m});var o=n(6540);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,o,r=function(e,t){if(null==e)return{};var n,o,r={},a=Object.keys(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var c=o.createContext({}),s=function(e){var t=o.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},d=function(e){var t=s(e.components);return o.createElement(c.Provider,{value:t},e.children)},p="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},g=o.forwardRef((function(e,t){var n=e.components,r=e.mdxType,a=e.originalType,c=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),p=s(n),g=r,m=p["".concat(c,".").concat(g)]||p[g]||u[g]||a;return n?o.createElement(m,i(i({ref:t},d),{},{components:n})):o.createElement(m,i({ref:t},d))}));function m(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var a=n.length,i=new Array(a);i[0]=g;var l={};for(var c in t)hasOwnProperty.call(t,c)&&(l[c]=t[c]);l.originalType=e,l[p]="string"==typeof e?e:r,i[1]=l;for(var s=2;s<a;s++)i[s]=n[s];return o.createElement.apply(null,i)}return o.createElement.apply(null,n)}g.displayName="MDXCreateElement"},9978:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>u,frontMatter:()=>a,metadata:()=>l,toc:()=>s});var o=n(8168),r=(n(6540),n(5680));const a={title:"useObjectDetection",sidebar_position:2},i=void 0,l={unversionedId:"computer-vision/useObjectDetection",id:"computer-vision/useObjectDetection",title:"useObjectDetection",description:"Object detection is a computer vision technique that identifies and locates objects within images or video. It\u2019s commonly used in applications like image recognition, video surveillance or autonomous driving.",source:"@site/docs/computer-vision/useObjectDetection.mdx",sourceDirName:"computer-vision",slug:"/computer-vision/useObjectDetection",permalink:"/react-native-executorch/docs/computer-vision/useObjectDetection",draft:!1,editUrl:"https://github.com/software-mansion/react-native-executorch/edit/main/docs/docs/computer-vision/useObjectDetection.mdx",tags:[],version:"current",sidebarPosition:2,frontMatter:{title:"useObjectDetection",sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"useClassification",permalink:"/react-native-executorch/docs/computer-vision/useClassification"},next:{title:"useStyleTransfer",permalink:"/react-native-executorch/docs/computer-vision/useStyleTransfer"}},c={},s=[{value:"Reference",id:"reference",level:2},{value:"Arguments",id:"arguments",level:3},{value:"Returns",id:"returns",level:3},{value:"Running the model",id:"running-the-model",level:2},{value:"Detection object",id:"detection-object",level:2},{value:"Example",id:"example",level:2},{value:"Supported models",id:"supported-models",level:2}],d={toc:s},p="wrapper";function u(e){let{components:t,...n}=e;return(0,r.yg)(p,(0,o.A)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,r.yg)("p",null,"Object detection is a computer vision technique that identifies and locates objects within images or video. It\u2019s commonly used in applications like image recognition, video surveillance or autonomous driving.\n",(0,r.yg)("inlineCode",{parentName:"p"},"useObjectDetection")," is a hook that allows you to seamlessly integrate object detection into your React Native applications."),(0,r.yg)("admonition",{type:"caution"},(0,r.yg)("p",{parentName:"admonition"},"It is recommended to use models provided by us, which are available at our ",(0,r.yg)("a",{parentName:"p",href:"https://huggingface.co/software-mansion/react-native-executorch-ssdlite320-mobilenet-v3-large"},"Hugging Face repository"),". You can also use ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/software-mansion/react-native-executorch/blob/69802ee1ca161d9df00def1dabe014d36341cfa9/src/constants/modelUrls.ts#L28"},"constants")," shipped with our library.")),(0,r.yg)("h2",{id:"reference"},"Reference"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-jsx"},'import { useObjectDetection, SSDLITE_320_MOBILENET_V3_LARGE } from \'react-native-executorch\';\n\nfunction App() {\n  const ssdlite = useObjectDetection({\n    modelSource: SSDLITE_320_MOBILENET_V3_LARGE, // alternatively, you can use require(...)\n  });\n\n  ...\n  for (const detection of await ssdlite.forward("https://url-to-image.jpg")) {\n    console.log("Bounding box: ", detection.bbox);\n    console.log("Bounding label: ", detection.label);\n    console.log("Bounding score: ", detection.score);\n  }\n  ...\n}\n')),(0,r.yg)("details",null,(0,r.yg)("summary",null,"Type definitions"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-typescript"},"interface Bbox {\n  x1: number;\n  x2: number;\n  y1: number;\n  y2: number;\n}\n\ninterface Detection {\n  bbox: Bbox;\n  label: keyof typeof CocoLabel;\n  score: number;\n}\n\ninterface ObjectDetectionModule {\n  error: string | null;\n  isReady: boolean;\n  isGenerating: boolean;\n  forward: (input: string) => Promise<Detection[]>;\n}\n"))),(0,r.yg)("h3",{id:"arguments"},"Arguments"),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"modelSource")),(0,r.yg)("p",null,"A string that specifies the path to the model file. You can download the model from our ",(0,r.yg)("a",{parentName:"p",href:"https://huggingface.co/software-mansion/react-native-executorch-ssdlite320-mobilenet-v3-large/tree/main"},"HuggingFace repository"),".\nFor more information on that topic, you can check out the ",(0,r.yg)("a",{parentName:"p",href:"https://docs.swmansion.com/react-native-executorch/fundamentals/loading-models"},"Loading models")," page."),(0,r.yg)("h3",{id:"returns"},"Returns"),(0,r.yg)("p",null,"The hook returns an object with the following properties:"),(0,r.yg)("table",null,(0,r.yg)("thead",{parentName:"table"},(0,r.yg)("tr",{parentName:"thead"},(0,r.yg)("th",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"th"},"Field")),(0,r.yg)("th",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"th"},"Type")),(0,r.yg)("th",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"th"},"Description")))),(0,r.yg)("tbody",{parentName:"table"},(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"forward")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"(input: string) => Promise<Detection[]>")),(0,r.yg)("td",{parentName:"tr",align:null},"A function that accepts an image (url, b64) and returns an array of ",(0,r.yg)("inlineCode",{parentName:"td"},"Detection")," objects.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"error")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("code",null,"string ","|"," null")),(0,r.yg)("td",{parentName:"tr",align:null},"Contains the error message if the model loading failed.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"isGenerating")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"boolean")),(0,r.yg)("td",{parentName:"tr",align:null},"Indicates whether the model is currently processing an inference.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"isReady")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"boolean")),(0,r.yg)("td",{parentName:"tr",align:null},"Indicates whether the model has successfully loaded and is ready for inference.")))),(0,r.yg)("h2",{id:"running-the-model"},"Running the model"),(0,r.yg)("p",null,"To run the model, you can use the ",(0,r.yg)("inlineCode",{parentName:"p"},"forward")," method. It accepts one argument, which is the image. The image can be a remote URL, a local file URI, or a base64-encoded image. The function returns an array of ",(0,r.yg)("inlineCode",{parentName:"p"},"Detection")," objects. Each object contains coordinates of the bounding box, the label of the detected object, and the confidence score. For more information, please refer to the reference or type definitions."),(0,r.yg)("h2",{id:"detection-object"},"Detection object"),(0,r.yg)("p",null,"The detection object is specified as follows:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-typescript"},"interface Bbox {\n  x1: number;\n  y1: number;\n  x2: number;\n  y2: number;\n}\n\ninterface Detection {\n  bbox: Bbox;\n  label: keyof typeof CocoLabels;\n  score: number;\n}\n")),(0,r.yg)("p",null,"The ",(0,r.yg)("inlineCode",{parentName:"p"},"bbox")," property contains information about the bounding box of detected objects. It is represented as two points: one at the bottom-left corner of the bounding box (",(0,r.yg)("inlineCode",{parentName:"p"},"x1"),", ",(0,r.yg)("inlineCode",{parentName:"p"},"y1"),") and the other at the top-right corner (",(0,r.yg)("inlineCode",{parentName:"p"},"x2"),", ",(0,r.yg)("inlineCode",{parentName:"p"},"y2"),").\nThe ",(0,r.yg)("inlineCode",{parentName:"p"},"label")," property contains the name of the detected object, which corresponds to one of the ",(0,r.yg)("inlineCode",{parentName:"p"},"CocoLabels"),". The ",(0,r.yg)("inlineCode",{parentName:"p"},"score")," represents the confidence score of the detected object."),(0,r.yg)("h2",{id:"example"},"Example"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-tsx"},'import { useObjectDetection, SSDLITE_320_MOBILENET_V3_LARGE } from \'react-native-executorch\';\n\nfunction App() {\n  const ssdlite = useObjectDetection({\n    modelSource: SSDLITE_320_MOBILENET_V3_LARGE,\n  });\n\n  const runModel = async () => {\n    const detections = await ssdlite.forward("https://url-to-image.jpg");\n    for (const detection of detections) {\n      console.log("Bounding box: ", detection.bbox);\n      console.log("Bounding label: ", detection.label);\n      console.log("Bounding score: ", detection.score);\n    }\n  }\n}\n')),(0,r.yg)("h2",{id:"supported-models"},"Supported models"),(0,r.yg)("table",null,(0,r.yg)("thead",{parentName:"table"},(0,r.yg)("tr",{parentName:"thead"},(0,r.yg)("th",{parentName:"tr",align:null},"Model"),(0,r.yg)("th",{parentName:"tr",align:null},"Number of classes"),(0,r.yg)("th",{parentName:"tr",align:null},"Class list"))),(0,r.yg)("tbody",{parentName:"table"},(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("a",{parentName:"td",href:"https://pytorch.org/vision/main/models/generated/torchvision.models.detection.ssdlite320_mobilenet_v3_large.html#torchvision.models.detection.SSDLite320_MobileNet_V3_Large_Weights"},"SSDLite320 MobileNetV3 Large")),(0,r.yg)("td",{parentName:"tr",align:null},"91"),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("a",{parentName:"td",href:"https://github.com/software-mansion/react-native-executorch/blob/69802ee1ca161d9df00def1dabe014d36341cfa9/src/types/object_detection.ts#L14"},"COCO"))))))}u.isMDXComponent=!0}}]);