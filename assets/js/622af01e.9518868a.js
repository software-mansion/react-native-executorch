"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[472],{5680:(e,t,n)=>{n.d(t,{xA:()=>d,yg:()=>m});var r=n(6540);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var c=r.createContext({}),s=function(e){var t=r.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},d=function(e){var t=s(e.components);return r.createElement(c.Provider,{value:t},e.children)},g="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},u=r.forwardRef((function(e,t){var n=e.components,o=e.mdxType,a=e.originalType,c=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),g=s(n),u=o,m=g["".concat(c,".").concat(u)]||g[u]||p[u]||a;return n?r.createElement(m,i(i({ref:t},d),{},{components:n})):r.createElement(m,i({ref:t},d))}));function m(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=n.length,i=new Array(a);i[0]=u;var l={};for(var c in t)hasOwnProperty.call(t,c)&&(l[c]=t[c]);l.originalType=e,l[g]="string"==typeof e?e:o,i[1]=l;for(var s=2;s<a;s++)i[s]=n[s];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}u.displayName="MDXCreateElement"},8954:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>p,frontMatter:()=>a,metadata:()=>l,toc:()=>s});var r=n(8168),o=(n(6540),n(5680));const a={title:"VerticalOCRModule",sidebar_position:7},i=void 0,l={unversionedId:"hookless-api/VerticalOCRModule",id:"hookless-api/VerticalOCRModule",title:"VerticalOCRModule",description:"Hookless implementation of the useVerticalOCR hook.",source:"@site/docs/hookless-api/VerticalOCRModule.md",sourceDirName:"hookless-api",slug:"/hookless-api/VerticalOCRModule",permalink:"/react-native-executorch/docs/hookless-api/VerticalOCRModule",draft:!1,editUrl:"https://github.com/software-mansion/react-native-executorch/edit/main/docs/docs/hookless-api/VerticalOCRModule.md",tags:[],version:"current",sidebarPosition:7,frontMatter:{title:"VerticalOCRModule",sidebar_position:7},sidebar:"tutorialSidebar",previous:{title:"SpeechToTextModule",permalink:"/react-native-executorch/docs/hookless-api/SpeechToTextModule"},next:{title:"Module API",permalink:"/react-native-executorch/docs/category/module-api"}},c={},s=[{value:"Reference",id:"reference",level:2},{value:"Methods",id:"methods",level:3},{value:"Loading the model",id:"loading-the-model",level:2},{value:"Listening for download progress",id:"listening-for-download-progress",level:2},{value:"Running the model",id:"running-the-model",level:2}],d={toc:s},g="wrapper";function p(e){let{components:t,...n}=e;return(0,o.yg)(g,(0,r.A)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Hookless implementation of the ",(0,o.yg)("a",{parentName:"p",href:"/react-native-executorch/docs/computer-vision/useVerticalOCR"},"useVerticalOCR")," hook."),(0,o.yg)("h2",{id:"reference"},"Reference"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-typescript"},"import {\n  DETECTOR_CRAFT_1280,\n  DETECTOR_CRAFT_320,\n  RECOGNIZER_EN_CRNN_512,\n  RECOGNIZER_EN_CRNN_64,\n  useVerticalOCR,\n} from 'react-native-executorch';\n\nconst imageUri = 'path/to/image.png';\n\n// Loading the model\nawait VerticalOCRModule.load({\n  detectorSources: {\n    detectorLarge: DETECTOR_CRAFT_1280,\n    detectorNarrow: DETECTOR_CRAFT_320,\n  },\n  recognizerSources: {\n    recognizerLarge: RECOGNIZER_EN_CRNN_512,\n    recognizerSmall: RECOGNIZER_EN_CRNN_64,\n  },\n  language: 'en',\n  independentCharacters: true,\n});\n\n// Running the model\nconst ocrDetections = await VerticalOCRModule.forward(imageUri);\n")),(0,o.yg)("h3",{id:"methods"},"Methods"),(0,o.yg)("table",null,(0,o.yg)("thead",{parentName:"table"},(0,o.yg)("tr",{parentName:"thead"},(0,o.yg)("th",{parentName:"tr",align:null},"Method"),(0,o.yg)("th",{parentName:"tr",align:null},"Type"),(0,o.yg)("th",{parentName:"tr",align:null},"Description"))),(0,o.yg)("tbody",{parentName:"table"},(0,o.yg)("tr",{parentName:"tbody"},(0,o.yg)("td",{parentName:"tr",align:null},(0,o.yg)("inlineCode",{parentName:"td"},"load")),(0,o.yg)("td",{parentName:"tr",align:null},(0,o.yg)("inlineCode",{parentName:"td"},"(detectorSources: DetectorSources, recognizerSources: RecognizerSources, language: OCRLanguage independentCharacters: boolean): Promise<void>")),(0,o.yg)("td",{parentName:"tr",align:null},"Loads detectors and recognizers, which sources are represented by ",(0,o.yg)("inlineCode",{parentName:"td"},"DetectorSources")," and ",(0,o.yg)("inlineCode",{parentName:"td"},"RecognizerSources"),".")),(0,o.yg)("tr",{parentName:"tbody"},(0,o.yg)("td",{parentName:"tr",align:null},(0,o.yg)("inlineCode",{parentName:"td"},"forward")),(0,o.yg)("td",{parentName:"tr",align:null},(0,o.yg)("inlineCode",{parentName:"td"},"(input: string): Promise<OCRDetections[]>")),(0,o.yg)("td",{parentName:"tr",align:null},"Executes the model's forward pass, where ",(0,o.yg)("inlineCode",{parentName:"td"},"input")," can be a fetchable resource or a Base64-encoded string.")),(0,o.yg)("tr",{parentName:"tbody"},(0,o.yg)("td",{parentName:"tr",align:null},(0,o.yg)("inlineCode",{parentName:"td"},"onDownloadProgress")),(0,o.yg)("td",{parentName:"tr",align:null},(0,o.yg)("inlineCode",{parentName:"td"},"(callback: (downloadProgress: number) => void): any")),(0,o.yg)("td",{parentName:"tr",align:null},"Subscribe to the download progress event.")))),(0,o.yg)("details",null,(0,o.yg)("summary",null,"Type definitions"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-typescript"},"interface DetectorSources {\n  detectorLarge: string | number;\n  detectorNarrow: string | number;\n}\n\ninterface RecognizerSources {\n  recognizerLarge: string | number;\n  recognizerSmall: string | number;\n}\n\ntype OCRLanguage = 'en';\n\ninterface Point {\n  x: number;\n  y: number;\n}\n\ninterface OCRDetection {\n  bbox: Point[];\n  text: string;\n  score: number;\n}\n"))),(0,o.yg)("h2",{id:"loading-the-model"},"Loading the model"),(0,o.yg)("p",null,"To load the model, use the ",(0,o.yg)("inlineCode",{parentName:"p"},"load")," method. It accepts:"),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},(0,o.yg)("inlineCode",{parentName:"strong"},"detectorSources"))," - An object that specifies the location of the detectors binary files. Each detector is composed of two models tailored to process images of varying widths."),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("inlineCode",{parentName:"li"},"detectorLarge")," - A string that specifies the location of the recognizer binary file which accepts input images with a width of 1280 pixels."),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("inlineCode",{parentName:"li"},"detectorNarrow")," - A string that specifies the location of the detector binary file which accepts input images with a width of 320 pixels.")),(0,o.yg)("p",null,"For more information, take a look at ",(0,o.yg)("a",{parentName:"p",href:"/react-native-executorch/docs/fundamentals/loading-models"},"loading models")," section."),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},(0,o.yg)("inlineCode",{parentName:"strong"},"recognizerSources"))," - An object that specifies the locations of the recognizers binary files. Each recognizer is composed of two models tailored to process images of varying widths."),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("inlineCode",{parentName:"li"},"recognizerLarge")," - A string that specifies the location of the recognizer binary file which accepts input images with a width of 512 pixels."),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("inlineCode",{parentName:"li"},"recognizerSmall")," - A string that specifies the location of the recognizer binary file which accepts input images with a width of 64 pixels.")),(0,o.yg)("p",null,"For more information, take a look at ",(0,o.yg)("a",{parentName:"p",href:"/react-native-executorch/docs/fundamentals/loading-models"},"loading models")," section."),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},(0,o.yg)("inlineCode",{parentName:"strong"},"language"))," - A parameter that specifies the language of the text to be recognized by the OCR."),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},(0,o.yg)("inlineCode",{parentName:"strong"},"independentCharacters"))," \u2013 A boolean parameter that indicates whether the text in the image consists of a random sequence of characters. If set to true, the algorithm will scan each character individually instead of reading them as continuous text."),(0,o.yg)("p",null,"This method returns a promise, which can resolve to an error or void."),(0,o.yg)("h2",{id:"listening-for-download-progress"},"Listening for download progress"),(0,o.yg)("p",null,"To subscribe to the download progress event, you can use the ",(0,o.yg)("inlineCode",{parentName:"p"},"onDownloadProgress")," method. It accepts a callback function that will be called whenever the download progress changes."),(0,o.yg)("h2",{id:"running-the-model"},"Running the model"),(0,o.yg)("p",null,"To run the model, you can use the ",(0,o.yg)("inlineCode",{parentName:"p"},"forward")," method. It accepts one argument, which is the image. The image can be a remote URL, a local file URI, or a base64-encoded image. The method returns a promise, which can resolve either to an error or an array of ",(0,o.yg)("inlineCode",{parentName:"p"},"OCRDetection")," objects. Each object contains coordinates of the bounding box, the label of the detected object, and the confidence score."))}p.isMDXComponent=!0}}]);