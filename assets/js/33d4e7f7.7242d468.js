"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[2092],{4783:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>c,default:()=>h,frontMatter:()=>i,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"typescript-api/natural-language-processing/TextToSpeechModule","title":"TextToSpeechModule","description":"TypeScript API implementation of the useTextToSpeech hook.","source":"@site/docs/04-typescript-api/01-natural-language-processing/TextToSpeechModule.md","sourceDirName":"04-typescript-api/01-natural-language-processing","slug":"/typescript-api/natural-language-processing/TextToSpeechModule","permalink":"/react-native-executorch/docs/next/typescript-api/natural-language-processing/TextToSpeechModule","draft":false,"unlisted":false,"editUrl":"https://github.com/software-mansion/react-native-executorch/edit/main/docs/docs/04-typescript-api/01-natural-language-processing/TextToSpeechModule.md","tags":[],"version":"current","frontMatter":{"title":"TextToSpeechModule"},"sidebar":"tutorialSidebar","previous":{"title":"TextEmbeddingsModule","permalink":"/react-native-executorch/docs/next/typescript-api/natural-language-processing/TextEmbeddingsModule"},"next":{"title":"TokenizerModule","permalink":"/react-native-executorch/docs/next/typescript-api/natural-language-processing/TokenizerModule"}}');var r=t(4848),s=t(8453);const i={title:"TextToSpeechModule"},c=void 0,a={},d=[{value:"Reference",id:"reference",level:2},{value:"Methods",id:"methods",level:3},{value:"Loading the model",id:"loading-the-model",level:2},{value:"Running the model",id:"running-the-model",level:2},{value:"Example",id:"example",level:2},{value:"Speech Synthesis",id:"speech-synthesis",level:3},{value:"Streaming Synthesis",id:"streaming-synthesis",level:3}];function l(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components},{Details:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(n.p,{children:["TypeScript API implementation of the ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/hooks/natural-language-processing/useTextToSpeech",children:"useTextToSpeech"})," hook."]}),"\n",(0,r.jsx)(n.h2,{id:"reference",children:"Reference"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"import {\n  TextToSpeechModule,\n  KOKORO_MEDIUM,\n  KOKORO_VOICE_AF_HEART,\n} from 'react-native-executorch';\n\nconst model = new TextToSpeechModule();\nawait model.load(\n  {\n    model: KOKORO_MEDIUM,\n    voice: KOKORO_VOICE_AF_HEART,\n  },\n  (progress) => {\n    console.log(progress);\n  }\n);\n\nawait model.forward(text, 1.0);\n"})}),"\n",(0,r.jsx)(n.h3,{id:"methods",children:"Methods"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Method"}),(0,r.jsx)(n.th,{children:"Type"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"load"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"(config: TextToSpeechConfig, onDownloadProgressCallback?: (progress: number) => void): Promise<void>"})}),(0,r.jsxs)(n.td,{children:["Loads the model and voice assets specified by the config object. ",(0,r.jsx)(n.code,{children:"onDownloadProgressCallback"})," allows you to monitor the current progress."]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"delete"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"(): void"})}),(0,r.jsx)(n.td,{children:"Unloads the model from memory."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"forward"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"(text: string, speed?: number): Promise<Float32Array>"})}),(0,r.jsxs)(n.td,{children:["Synthesizes the provided text into speech. Returns a promise that resolves to the full audio waveform as a ",(0,r.jsx)(n.code,{children:"Float32Array"}),"."]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"stream"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"(input: TextToSpeechStreamingInput): AsyncGenerator<Float32Array>"})}),(0,r.jsx)(n.td,{children:"Starts a streaming synthesis session. Yields audio chunks as they are generated."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"streamStop"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"(): void"})}),(0,r.jsx)(n.td,{children:"Stops the streaming process if there is any ongoing."})]})]})]}),"\n",(0,r.jsxs)(t,{children:[(0,r.jsx)("summary",{children:"Type definitions"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"interface TextToSpeechConfig {\n  model: KokoroConfig;\n  voice: VoiceConfig;\n}\n\ninterface TextToSpeechStreamingInput {\n  text: string;\n  speed?: number;\n  onBegin?: () => void | Promise<void>;\n  onNext?: (chunk: Float32Array) => Promise<void> | void;\n  onEnd?: () => Promise<void> | void;\n}\n"})})]}),"\n",(0,r.jsx)(n.h2,{id:"loading-the-model",children:"Loading the model"}),"\n",(0,r.jsxs)(n.p,{children:["To initialize the module, create an instance and call the ",(0,r.jsx)(n.code,{children:"load"})," method with a configuration object. This method returns a promise that resolves once the assets are downloaded and loaded into memory."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"config"})})," - Object containing:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"model"})})," (",(0,r.jsx)(n.code,{children:"KokoroConfig"}),"): Specifies the source files for the Kokoro TTS model (duration predictor, synthesizer)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"voice"})})," (",(0,r.jsx)(n.code,{children:"VoiceConfig"}),"): Specifies the voice data and additional phonemizer assets (tagger and lexicon). Each voice is associated with a concrete speech language."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"onDownloadProgressCallback"})})," - (Optional) A callback function to track the download progress of the model and voice assets."]}),"\n",(0,r.jsxs)(n.p,{children:["For more information on resource sources, see ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/fundamentals/loading-models",children:"loading models"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"running-the-model",children:"Running the model"}),"\n",(0,r.jsx)(n.p,{children:"The module provides two ways to generate speech:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"forward(text, speed)"})}),": Generates the complete audio waveform at once. Returns a promise resolving to a ",(0,r.jsx)(n.code,{children:"Float32Array"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsx)(n.p,{children:"Since it processes the entire text at once, it might take a significant amount of time to produce an audio for long text inputs."})}),"\n",(0,r.jsxs)(n.ol,{start:"2",children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"stream({ text, speed })"})}),': An async generator that yields chunks of audio as they are computed.\nThis is ideal for reducing the "time to first audio" for long sentences.']}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"example",children:"Example"}),"\n",(0,r.jsx)(n.h3,{id:"speech-synthesis",children:"Speech Synthesis"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"import {\n  TextToSpeechModule,\n  KOKORO_MEDIUM,\n  KOKORO_VOICE_AF_HEART,\n} from 'react-native-executorch';\nimport { AudioContext } from 'react-native-audio-api';\n\nconst tts = new TextToSpeechModule();\nconst audioContext = new AudioContext({ sampleRate: 24000 });\n\ntry {\n  await tts.load({\n    model: KOKORO_MEDIUM,\n    voice: KOKORO_VOICE_AF_HEART,\n  });\n\n  const waveform = await tts.forward('Hello from ExecuTorch!', 1.0);\n\n  // Create audio buffer and play\n  const audioBuffer = audioContext.createBuffer(1, waveform.length, 24000);\n  audioBuffer.getChannelData(0).set(waveform);\n\n  const source = audioContext.createBufferSource();\n  source.buffer = audioBuffer;\n  source.connect(audioContext.destination);\n  source.start();\n} catch (error) {\n  console.error('Text-to-speech failed:', error);\n}\n"})}),"\n",(0,r.jsx)(n.h3,{id:"streaming-synthesis",children:"Streaming Synthesis"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"import {\n  TextToSpeechModule,\n  KOKORO_MEDIUM,\n  KOKORO_VOICE_AF_HEART,\n} from 'react-native-executorch';\nimport { AudioContext } from 'react-native-audio-api';\n\nconst tts = new TextToSpeechModule();\nconst audioContext = new AudioContext({ sampleRate: 24000 });\n\nawait tts.load({ model: KOKORO_MEDIUM, voice: KOKORO_VOICE_AF_HEART });\n\ntry {\n  for await (const chunk of tts.stream({\n    text: 'This is a streaming test, with a sample input.',\n    speed: 1.0,\n  })) {\n    // Play each chunk sequentially\n    await new Promise<void>((resolve) => {\n      const audioBuffer = audioContext.createBuffer(1, chunk.length, 24000);\n      audioBuffer.getChannelData(0).set(chunk);\n\n      const source = audioContext.createBufferSource();\n      source.buffer = audioBuffer;\n      source.connect(audioContext.destination);\n      source.onEnded = () => resolve();\n      source.start();\n    });\n  }\n} catch (error) {\n  console.error('Streaming failed:', error);\n}\n"})})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>c});var o=t(6540);const r={},s=o.createContext(r);function i(e){const n=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);