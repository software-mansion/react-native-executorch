"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[39662],{28453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>s});var o=t(96540);const r={},c=o.createContext(r);function i(e){const n=o.useContext(c);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),o.createElement(c.Provider,{value:n},e.children)}},46395:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>s,default:()=>h,frontMatter:()=>i,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"hooks/computer-vision/useOCR","title":"useOCR","description":"Optical character recognition (OCR) is a computer vision technique that detects and recognizes text within the image. It\'s commonly used to convert different types of documents, such as scanned paper documents, PDF files, or images captured by a digital camera, into editable and searchable data.","source":"@site/versioned_docs/version-0.7.x/03-hooks/02-computer-vision/useOCR.md","sourceDirName":"03-hooks/02-computer-vision","slug":"/hooks/computer-vision/useOCR","permalink":"/react-native-executorch/docs/hooks/computer-vision/useOCR","draft":false,"unlisted":false,"editUrl":"https://github.com/software-mansion/react-native-executorch/edit/main/docs/versioned_docs/version-0.7.x/03-hooks/02-computer-vision/useOCR.md","tags":[],"version":"0.7.x","frontMatter":{"title":"useOCR"},"sidebar":"tutorialSidebar","previous":{"title":"useImageSegmentation","permalink":"/react-native-executorch/docs/hooks/computer-vision/useImageSegmentation"},"next":{"title":"useObjectDetection","permalink":"/react-native-executorch/docs/hooks/computer-vision/useObjectDetection"}}');var r=t(74848),c=t(28453);const i={title:"useOCR"},s=void 0,a={},d=[{value:"API Reference",id:"api-reference",level:2},{value:"High Level Overview",id:"high-level-overview",level:2},{value:"Arguments",id:"arguments",level:3},{value:"Returns",id:"returns",level:3},{value:"Running the model",id:"running-the-model",level:2},{value:"Detection object",id:"detection-object",level:2},{value:"Example",id:"example",level:2},{value:"Alphabet-Specific Recognizers",id:"alphabet-specific-recognizers",level:2},{value:"Supported languages",id:"supported-languages",level:2},{value:"Supported models",id:"supported-models",level:2}];function l(e){const n={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,c.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.p,{children:"Optical character recognition (OCR) is a computer vision technique that detects and recognizes text within the image. It's commonly used to convert different types of documents, such as scanned paper documents, PDF files, or images captured by a digital camera, into editable and searchable data."}),"\n",(0,r.jsx)(n.admonition,{type:"warning",children:(0,r.jsxs)(n.p,{children:["It is recommended to use models provided by us, which are available at our ",(0,r.jsx)(n.a,{href:"https://huggingface.co/collections/software-mansion/ocr-68d0eb320ae6d20b5f901ea9",children:"Hugging Face repository"}),". You can also use ",(0,r.jsx)(n.a,{href:"https://github.com/software-mansion/react-native-executorch/blob/main/packages/react-native-executorch/src/constants/modelUrls.ts",children:"constants"})," shipped with our library."]})}),"\n",(0,r.jsx)(n.h2,{id:"api-reference",children:"API Reference"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["For detailed API Reference for ",(0,r.jsx)(n.code,{children:"useOCR"})," see: ",(0,r.jsxs)(n.a,{href:"/react-native-executorch/docs/api-reference/functions/useOCR",children:[(0,r.jsx)(n.code,{children:"useOCR"})," API Reference"]}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["For all alphabets available in ocr out-of-the-box in React Native ExecuTorch see: ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/api-reference/#ocr-supported-alphabets",children:"OCR Supported Alphabets"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"high-level-overview",children:"High Level Overview"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-tsx",children:"import { useOCR, OCR_ENGLISH } from 'react-native-executorch';\n\nfunction App() {\n  const model = useOCR({ model: OCR_ENGLISH });\n\n  // ...\n  for (const ocrDetection of await model.forward('https://url-to-image.jpg')) {\n    console.log('Bounding box: ', ocrDetection.bbox);\n    console.log('Bounding label: ', ocrDetection.text);\n    console.log('Bounding score: ', ocrDetection.score);\n  }\n  // ...\n}\n"})}),"\n",(0,r.jsx)(n.h3,{id:"arguments",children:"Arguments"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"useOCR"})," takes ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/api-reference/interfaces/OCRProps",children:(0,r.jsx)(n.code,{children:"OCRProps"})})," that consists of:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"model"})," containing ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/api-reference/interfaces/OCRProps#detectorsource",children:(0,r.jsx)(n.code,{children:"detectorSource"})}),", ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/api-reference/interfaces/OCRProps#recognizersource",children:(0,r.jsx)(n.code,{children:"recognizerSource"})}),", and ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/api-reference/interfaces/OCRProps#language",children:(0,r.jsx)(n.code,{children:"language"})}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["An optional flag ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/api-reference/interfaces/OCRProps#preventload",children:(0,r.jsx)(n.code,{children:"preventLoad"})})," which prevents auto-loading of the model."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"You need more details? Check the following resources:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["For detailed information about ",(0,r.jsx)(n.code,{children:"useOCR"})," arguments check this section: ",(0,r.jsxs)(n.a,{href:"/react-native-executorch/docs/api-reference/functions/useOCR#parameters",children:[(0,r.jsx)(n.code,{children:"useOCR"})," arguments"]}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["For all alphabets available in ocr out-of-the-box in React Native ExecuTorch see: ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/api-reference/#ocr-supported-alphabets",children:"OCR Supported Alphabets"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["For more information on loading resources, take a look at ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/fundamentals/loading-models",children:"loading models"})," page."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"returns",children:"Returns"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"useOCR"})," returns an object called ",(0,r.jsx)(n.code,{children:"OCRType"})," containing bunch of functions to interact with OCR models. To get more details please read: ",(0,r.jsxs)(n.a,{href:"/react-native-executorch/docs/api-reference/interfaces/OCRType",children:[(0,r.jsx)(n.code,{children:"OCRType"})," API Reference"]}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"running-the-model",children:"Running the model"}),"\n",(0,r.jsxs)(n.p,{children:["To run the model, you can use the ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/api-reference/interfaces/OCRType#forward",children:(0,r.jsx)(n.code,{children:"forward"})})," method. It accepts one argument, which is the image. The image can be a remote URL, a local file URI, or a base64-encoded image. The function returns an array of ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/api-reference/interfaces/OCRDetection",children:(0,r.jsx)(n.code,{children:"OCRDetection"})})," objects. Each object contains coordinates of the bounding box, the text recognized within the box, and the confidence score. For more information, please refer to the reference or type definitions."]}),"\n",(0,r.jsx)(n.h2,{id:"detection-object",children:"Detection object"}),"\n",(0,r.jsx)(n.p,{children:"The detection object is specified as follows:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"interface Point {\n  x: number;\n  y: number;\n}\n\ninterface OCRDetection {\n  bbox: Point[];\n  text: string;\n  score: number;\n}\n"})}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"bbox"})," property contains information about the bounding box of detected text regions. It is represented as four points, which are corners of detected bounding box.\nThe ",(0,r.jsx)(n.code,{children:"text"})," property contains the text recognized within detected text region. The ",(0,r.jsx)(n.code,{children:"score"})," represents the confidence score of the recognized text."]}),"\n",(0,r.jsx)(n.h2,{id:"example",children:"Example"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-tsx",children:"import { useOCR, OCR_ENGLISH } from 'react-native-executorch';\n\nfunction App() {\n  const model = useOCR({ model: OCR_ENGLISH });\n\n  const runModel = async () => {\n    const ocrDetections = await model.forward('https://url-to-image.jpg');\n\n    for (const ocrDetection of ocrDetections) {\n      console.log('Bounding box: ', ocrDetection.bbox);\n      console.log('Bounding text: ', ocrDetection.text);\n      console.log('Bounding score: ', ocrDetection.score);\n    }\n  };\n}\n"})}),"\n",(0,r.jsx)(n.h2,{id:"alphabet-specific-recognizers",children:"Alphabet-Specific Recognizers"}),"\n",(0,r.jsxs)(n.p,{children:["Each supported alphabet requires its own recognizer model. The built-in constants, such as ",(0,r.jsx)(n.code,{children:"RECOGNIZER_LATIN_CRNN"})," or ",(0,r.jsx)(n.code,{children:"RECOGNIZER_CYRILLIC_CRNN"}),", point to specific models trained for a particular alphabet."]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsx)(n.p,{children:"For example:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["To recognize text in languages using the ",(0,r.jsx)(n.strong,{children:"Latin"})," alphabet (like Polish, or German), use:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"RECOGNIZER_LATIN_CRNN"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["To recognize text in languages using the ",(0,r.jsx)(n.strong,{children:"Cyrillic"})," alphabet (like Russian or Ukrainian), use:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"RECOGNIZER_CYRILLIC_CRNN"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["You need to make sure the recognizer model you pass in ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/api-reference/interfaces/OCRProps#recognizersource",children:(0,r.jsx)(n.code,{children:"recognizerSource"})})," matches the alphabet of the ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/api-reference/interfaces/OCRProps#language",children:(0,r.jsx)(n.code,{children:"language"})})," you specify."]}),"\n",(0,r.jsx)(n.h2,{id:"supported-languages",children:"Supported languages"}),"\n",(0,r.jsxs)(n.p,{children:["For all alphabets available in ocr out-of-the-box in React Native ExecuTorch see: ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/api-reference/#ocr-supported-alphabets",children:"OCR Supported Alphabets"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"supported-models",children:"Supported models"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Model"}),(0,r.jsx)(n.th,{style:{textAlign:"center"},children:"Type"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.a,{href:"https://github.com/clovaai/CRAFT-pytorch",children:"CRAFT"})}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"Detector"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.a,{href:"https://www.jaided.ai/easyocr/modelhub/",children:"CRNN"})}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"Recognizer"})]})]})]})]})}function h(e={}){const{wrapper:n}={...(0,c.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}}}]);