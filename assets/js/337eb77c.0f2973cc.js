"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[2746],{28453:(e,r,n)=>{n.d(r,{R:()=>i,x:()=>s});var t=n(96540);const o={},c=t.createContext(o);function i(e){const r=t.useContext(c);return t.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function s(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),t.createElement(c.Provider,{value:r},e.children)}},87708:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>a,contentTitle:()=>s,default:()=>h,frontMatter:()=>i,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"typescript-api/executorch-bindings/ExecutorchModule","title":"ExecutorchModule","description":"ExecutorchModule provides TypeScript bindings for the underlying ExecuTorch Module API.","source":"@site/docs/04-typescript-api/03-executorch-bindings/ExecutorchModule.md","sourceDirName":"04-typescript-api/03-executorch-bindings","slug":"/typescript-api/executorch-bindings/ExecutorchModule","permalink":"/react-native-executorch/docs/next/typescript-api/executorch-bindings/ExecutorchModule","draft":false,"unlisted":false,"editUrl":"https://github.com/software-mansion/react-native-executorch/edit/main/docs/docs/04-typescript-api/03-executorch-bindings/ExecutorchModule.md","tags":[],"version":"current","frontMatter":{"title":"ExecutorchModule"},"sidebar":"tutorialSidebar","previous":{"title":"ExecuTorch Bindings","permalink":"/react-native-executorch/docs/next/category/executorch-bindings-1"},"next":{"title":"Error handling","permalink":"/react-native-executorch/docs/next/utilities/error-handling"}}');var o=n(74848),c=n(28453);const i={title:"ExecutorchModule"},s=void 0,a={},d=[{value:"API Reference",id:"api-reference",level:2},{value:"High Level Overview",id:"high-level-overview",level:2},{value:"Methods",id:"methods",level:3},{value:"TensorPtr",id:"tensorptr",level:2},{value:"End to end example",id:"end-to-end-example",level:2},{value:"Importing the Module and loading the model",id:"importing-the-module-and-loading-the-model",level:3},{value:"Setting up input parameters",id:"setting-up-input-parameters",level:3},{value:"Performing inference",id:"performing-inference",level:3}];function l(e){const r={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,c.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)(r.p,{children:["ExecutorchModule provides TypeScript bindings for the underlying ExecuTorch ",(0,o.jsx)(r.a,{href:"https://pytorch.org/executorch/stable/extension-module.html",children:"Module API"}),"."]}),"\n",(0,o.jsx)(r.admonition,{type:"tip",children:(0,o.jsxs)(r.p,{children:["For React applications, consider using the ",(0,o.jsx)(r.a,{href:"/react-native-executorch/docs/next/hooks/executorch-bindings/useExecutorchModule",children:(0,o.jsx)(r.code,{children:"useExecutorchModule"})})," hook instead, which provides automatic state management, loading progress tracking, and cleanup on unmount."]})}),"\n",(0,o.jsx)(r.h2,{id:"api-reference",children:"API Reference"}),"\n",(0,o.jsxs)(r.ul,{children:["\n",(0,o.jsxs)(r.li,{children:["For detailed API Reference for ",(0,o.jsx)(r.code,{children:"ExecutorchModule"})," see: ",(0,o.jsxs)(r.a,{href:"/react-native-executorch/docs/next/api-reference/classes/ExecutorchModule",children:[(0,o.jsx)(r.code,{children:"ExecutorchModule"})," API Reference"]}),"."]}),"\n"]}),"\n",(0,o.jsx)(r.h2,{id:"high-level-overview",children:"High Level Overview"}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-typescript",children:"import {\n  ExecutorchModule,\n  STYLE_TRANSFER_CANDY,\n  ScalarType,\n} from 'react-native-executorch';\n\n// Creating the input array\nconst inputTensor = {\n  dataPtr: new Float32Array(1 * 3 * 640 * 640),\n  sizes: [1, 3, 640, 640],\n  scalarType: ScalarType.FLOAT,\n};\n\n// Creating an instance\nconst model = new ExecutorchModule();\n\n// Loading the model\nawait model.load(STYLE_TRANSFER_CANDY);\n\n// Running the forward method\nconst output = await model.forward([inputTensor]);\n"})}),"\n",(0,o.jsx)(r.h3,{id:"methods",children:"Methods"}),"\n",(0,o.jsxs)(r.p,{children:["All methods of ",(0,o.jsx)(r.code,{children:"ExecutorchModule"})," are explained in details here: ",(0,o.jsxs)(r.a,{href:"/react-native-executorch/docs/next/api-reference/classes/ExecutorchModule",children:[(0,o.jsx)(r.code,{children:"ExecutorchModule"})," API Reference"]})]}),"\n",(0,o.jsx)(r.h2,{id:"tensorptr",children:"TensorPtr"}),"\n",(0,o.jsxs)(r.p,{children:["TensorPtr is a JS representation of the underlying tensor, which is then passed to the model. You can read more about creating tensors ",(0,o.jsx)(r.a,{href:"https://docs.pytorch.org/executorch/stable/extension-tensor.html",children:"here"}),". On JS side, the ",(0,o.jsx)(r.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/TensorPtr",children:(0,o.jsx)(r.code,{children:"TensorPtr"})})," holds the following information:"]}),"\n",(0,o.jsxs)(r.ul,{children:["\n",(0,o.jsxs)(r.li,{children:["\n",(0,o.jsxs)(r.p,{children:[(0,o.jsx)(r.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/TensorPtr#dataptr",children:(0,o.jsx)(r.code,{children:"dataPtr"})})," - Represents a data buffer that will be used to create a tensor on the native side. This can be either an ",(0,o.jsx)(r.code,{children:"ArrayBuffer"})," or a ",(0,o.jsx)(r.code,{children:"TypedArray"}),". If your model takes in a datatype which is not covered by any of the ",(0,o.jsx)(r.code,{children:"TypedArray"})," types, just pass an ",(0,o.jsx)(r.code,{children:"ArrayBuffer"})," here."]}),"\n"]}),"\n",(0,o.jsxs)(r.li,{children:["\n",(0,o.jsxs)(r.p,{children:[(0,o.jsx)(r.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/TensorPtr#sizes",children:(0,o.jsx)(r.code,{children:"sizes"})})," - Represents the shape of a given tensor, i.e. for a 640x640 RGB image with a batch size of 1, you would need to pass ",(0,o.jsx)(r.code,{children:"[1, 3, 640, 640]"})," here."]}),"\n"]}),"\n",(0,o.jsxs)(r.li,{children:["\n",(0,o.jsxs)(r.p,{children:[(0,o.jsx)(r.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/TensorPtr#scalartype",children:(0,o.jsx)(r.code,{children:"scalarType"})})," - An enum resembling the ExecuTorch's ",(0,o.jsx)(r.a,{href:"/react-native-executorch/docs/next/api-reference/enumerations/ScalarType",children:(0,o.jsx)(r.code,{children:"ScalarType"})}),". For example, if your model was exported with float32 as an input, you will need to pass ",(0,o.jsx)(r.a,{href:"/react-native-executorch/docs/next/api-reference/enumerations/ScalarType#float",children:(0,o.jsx)(r.code,{children:"ScalarType.FLOAT"})})," here."]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(r.h2,{id:"end-to-end-example",children:"End to end example"}),"\n",(0,o.jsxs)(r.p,{children:["This example demonstrates the integration and usage of the ExecuTorch bindings with a ",(0,o.jsx)(r.a,{href:"/react-native-executorch/docs/next/hooks/computer-vision/useStyleTransfer",children:"style transfer model"}),". Specifically, we'll be using the ",(0,o.jsx)(r.code,{children:"STYLE_TRANSFER_CANDY"})," model, which applies artistic style transfer to an input image."]}),"\n",(0,o.jsx)(r.h3,{id:"importing-the-module-and-loading-the-model",children:"Importing the Module and loading the model"}),"\n",(0,o.jsxs)(r.p,{children:["First, import the necessary functions from the ",(0,o.jsx)(r.code,{children:"react-native-executorch"})," package and initialize the ExecuTorch module with the specified style transfer model."]}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-typescript",children:"import {\n  ExecutorchModule,\n  STYLE_TRANSFER_CANDY,\n  ScalarType,\n} from 'react-native-executorch';\n\n// Initialize the executorch module\nconst executorchModule = new ExecutorchModule();\n\n// Load the model with optional download progress callback\nawait executorchModule.load(STYLE_TRANSFER_CANDY, (progress) => {\n  console.log(`Download progress: ${progress}%`);\n});\n"})}),"\n",(0,o.jsx)(r.h3,{id:"setting-up-input-parameters",children:"Setting up input parameters"}),"\n",(0,o.jsxs)(r.p,{children:["To prepare the model input, define the tensor shape according to your model's requirements (defined by the model export process). For example, the ",(0,o.jsx)(r.code,{children:"STYLE_TRANSFER_CANDY"})," model expects a tensor with shape ",(0,o.jsx)(r.code,{children:"[1, 3, 640, 640]"})," \u2014 representing a batch size of 1, 3 color channels (RGB), and 640\xd7640 pixel dimensions."]}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-typescript",children:"const inputTensor = {\n  dataPtr: new Float32Array(1 * 3 * 640 * 640), // or other TypedArray / ArrayBuffer\n  sizes: [1, 3, 640, 640],\n  scalarType: ScalarType.FLOAT,\n};\n"})}),"\n",(0,o.jsx)(r.h3,{id:"performing-inference",children:"Performing inference"}),"\n",(0,o.jsxs)(r.p,{children:["After passing input to the forward function, you'll receive an array of ",(0,o.jsx)(r.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/TensorPtr",children:(0,o.jsx)(r.code,{children:"TensorPtr"})})," objects. Each TensorPtr contains its ",(0,o.jsx)(r.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/TensorPtr#dataptr",children:(0,o.jsx)(r.code,{children:"dataPtr"})})," field as an ",(0,o.jsx)(r.code,{children:"ArrayBuffer"}),". Since ",(0,o.jsx)(r.code,{children:"ArrayBuffer"})," represents raw binary data, you'll need to interpret it according to the tensor's underlying data type (e.g., creating a ",(0,o.jsx)(r.code,{children:"Float32Array"})," view for float32 tensors, ",(0,o.jsx)(r.code,{children:"Int32Array"})," for int32 tensors, etc.)."]}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-typescript",children:"try {\n  // Perform the forward operation and receive the stylized image output.\n  const output = await executorchModule.forward([inputTensor]);\n  // Interpret the output ArrayBuffer\n  // foo(output[0].dataPtr);\n} catch (error) {\n  // Log any errors that occur during the forward pass.\n  console.error('Error during model execution:', error);\n}\n\n// Clean up resources when done\nexecutorchModule.delete();\n"})}),"\n",(0,o.jsx)(r.admonition,{type:"info",children:(0,o.jsx)(r.p,{children:"This code assumes that you have handled preprocessing of the input image (scaling, normalization) and postprocessing of the output (interpreting the raw output data) according to the model's requirements. Make sure to adjust these parts depending on your specific data and model outputs."})})]})}function h(e={}){const{wrapper:r}={...(0,c.R)(),...e.components};return r?(0,o.jsx)(r,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}}}]);