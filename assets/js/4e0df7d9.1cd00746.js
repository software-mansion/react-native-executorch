"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4826],{1982:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>d,default:()=>h,frontMatter:()=>s,metadata:()=>i,toc:()=>a});const i=JSON.parse('{"id":"module-api/executorch-bindings","title":"ExecuTorch Bindings","description":"ExecuTorch bindings provide streamlined interface to access the Module API directly from Javascript.","source":"@site/versioned_docs/version-0.2.x/module-api/executorch-bindings.md","sourceDirName":"module-api","slug":"/module-api/executorch-bindings","permalink":"/react-native-executorch/docs/0.2.x/module-api/executorch-bindings","draft":false,"unlisted":false,"editUrl":"https://github.com/software-mansion/react-native-executorch/edit/main/docs/versioned_docs/version-0.2.x/module-api/executorch-bindings.md","tags":[],"version":"0.2.x","sidebarPosition":1,"frontMatter":{"title":"ExecuTorch Bindings","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Module API","permalink":"/react-native-executorch/docs/0.2.x/category/module-api"}}');var t=r(4848),o=r(8453);const s={title:"ExecuTorch Bindings",sidebar_position:1},d=void 0,c={},a=[{value:"Intializing ExecuTorch Module",id:"intializing-executorch-module",level:2},{value:"Arguments",id:"arguments",level:3},{value:"Returns",id:"returns",level:3},{value:"ETInput",id:"etinput",level:3},{value:"Errors",id:"errors",level:3},{value:"Performing inference",id:"performing-inference",level:2},{value:"End to end example",id:"end-to-end-example",level:2},{value:"Importing the Module and loading the model",id:"importing-the-module-and-loading-the-model",level:3},{value:"Setting up input parameters",id:"setting-up-input-parameters",level:3},{value:"Performing inference",id:"performing-inference-1",level:3}];function l(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(n.p,{children:["ExecuTorch bindings provide streamlined interface to access the ",(0,t.jsx)(n.a,{href:"https://pytorch.org/executorch/stable/extension-module.html",children:"Module API"})," directly from Javascript."]}),"\n",(0,t.jsx)(n.admonition,{type:"caution",children:(0,t.jsx)(n.p,{children:"These bindings are primarily intended for custom model integration where no dedicated hook exists. If you are considering using a provided model, first verify whether a dedicated hook is available. Dedicated hooks simplify the implementation process by managing necessary pre and post-processing automatically. Utilizing these can save you effort and reduce complexity, ensuring you do not implement additional handling that is already covered."})}),"\n",(0,t.jsx)(n.h2,{id:"intializing-executorch-module",children:"Intializing ExecuTorch Module"}),"\n",(0,t.jsxs)(n.p,{children:["You can initialize the ExecuTorch module in your JavaScript application using the ",(0,t.jsx)(n.code,{children:"useExecutorchModule"})," hook. This hook facilitates the loading of models from the specified source and prepares them for use."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"import { useExecutorchModule } from 'react-native-executorch';\n\nconst executorchModule = useExecutorchModule({\n  modelSource: require('../assets/models/model.pte'),\n});\n"})}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"modelSource"})," parameter expects a location string pointing to the model binary. For more details on how to specify model sources, refer to the ",(0,t.jsx)(n.a,{href:"/react-native-executorch/docs/0.2.x/fundamentals/loading-models",children:"loading models"})," documentation."]}),"\n",(0,t.jsx)(n.h3,{id:"arguments",children:"Arguments"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"modelSource"})})," - A string that specifies the location of the model binary."]}),"\n",(0,t.jsx)(n.h3,{id:"returns",children:"Returns"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Field"}),(0,t.jsx)(n.th,{children:"Type"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"error"})}),(0,t.jsx)(n.td,{children:(0,t.jsx)("code",{children:"string | null"})}),(0,t.jsx)(n.td,{children:"Contains the error message if the model failed to load."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"isGenerating"})}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"boolean"})}),(0,t.jsx)(n.td,{children:"Indicates whether the model is currently processing an inference."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"isReady"})}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"boolean"})}),(0,t.jsx)(n.td,{children:"Indicates whether the model has successfully loaded and is ready for inference."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"loadMethod"})}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"(methodName: string) => Promise<void>"})}),(0,t.jsxs)(n.td,{children:["Loads resources specific to ",(0,t.jsx)(n.code,{children:"methodName"})," into memory before execution."]})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"loadForward"})}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"() => Promise<void>"})}),(0,t.jsxs)(n.td,{children:["Loads resources specific to ",(0,t.jsx)(n.code,{children:"forward"})," method into memory before execution. Uses ",(0,t.jsx)(n.code,{children:"loadMethod"})," under the hood."]})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"forward"})}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"(input: ETInput, shape: number[]) => Promise<number[][]>"})}),(0,t.jsxs)(n.td,{children:["Executes the model's forward pass, where ",(0,t.jsx)(n.code,{children:"input"})," is a Javascript typed array and ",(0,t.jsx)(n.code,{children:"shape"})," is an array of integers representing input Tensor shape. The output is a Tensor - raw result of inference."]})]})]})]}),"\n",(0,t.jsx)(n.h3,{id:"etinput",children:"ETInput"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"ETInput"})," type defines the typed arrays that can be used as inputs in the ",(0,t.jsx)(n.code,{children:"forward"})," method:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Int8Array"}),"\n",(0,t.jsx)(n.li,{children:"Int32Array"}),"\n",(0,t.jsx)(n.li,{children:"BigInt64Array"}),"\n",(0,t.jsx)(n.li,{children:"Float32Array"}),"\n",(0,t.jsx)(n.li,{children:"Float64Array"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"errors",children:"Errors"}),"\n",(0,t.jsxs)(n.p,{children:["All functions provided by the ",(0,t.jsx)(n.code,{children:"useExecutorchModule"})," hook are asynchronous and may throw an error. The ",(0,t.jsx)(n.code,{children:"ETError"})," enum includes errors ",(0,t.jsx)(n.a,{href:"https://github.com/pytorch/executorch/blob/release/0.7/runtime/core/error.h",children:"defined by the ExecuTorch team"})," and additional errors specified by our library."]}),"\n",(0,t.jsx)(n.h2,{id:"performing-inference",children:"Performing inference"}),"\n",(0,t.jsxs)(n.p,{children:["To run model with ExecuTorch Bindings it's essential to specify the shape of the input tensor. However, there's no need to explicitly define the input type, as it will automatically be inferred from the array you pass to ",(0,t.jsx)(n.code,{children:"forward"})," method. However you will still need to explicitly provide shape for the tensor. Outputs from the model, such as classification probabilities, are returned in raw format."]}),"\n",(0,t.jsx)(n.h2,{id:"end-to-end-example",children:"End to end example"}),"\n",(0,t.jsxs)(n.p,{children:["This example demonstrates the integration and usage of the ExecuTorch bindings with a ",(0,t.jsx)(n.a,{href:"/react-native-executorch/docs/0.2.x/computer-vision/useStyleTransfer",children:"style transfer model"}),". Specifically, we'll be using the ",(0,t.jsx)(n.code,{children:"STYLE_TRANSFER_CANDY"})," model, which applies artistic style transfer to an input image."]}),"\n",(0,t.jsx)(n.h3,{id:"importing-the-module-and-loading-the-model",children:"Importing the Module and loading the model"}),"\n",(0,t.jsxs)(n.p,{children:["First, import the necessary functions from the ",(0,t.jsx)(n.code,{children:"react-native-executorch"})," package and initialize the ExecuTorch module with the specified style transfer model."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"import {\n  useExecutorchModule,\n  STYLE_TRANSFER_CANDY,\n} from 'react-native-executorch';\n\n// Initialize the executorch module with the predefined style transfer model.\nconst executorchModule = useExecutorchModule({\n  modelSource: STYLE_TRANSFER_CANDY,\n});\n"})}),"\n",(0,t.jsx)(n.p,{children:"s"}),"\n",(0,t.jsx)(n.h3,{id:"setting-up-input-parameters",children:"Setting up input parameters"}),"\n",(0,t.jsxs)(n.p,{children:["To prepare the input for the model, define the shape of the input tensor. This shape depends on the model's requirements. For the ",(0,t.jsx)(n.code,{children:"STYLE_TRANSFER_CANDY"})," model, we need a tensor of shape ",(0,t.jsx)(n.code,{children:"[1, 3, 640, 640]"}),", corresponding to a batch size of 1, 3 color channels (RGB), and dimensions of 640x640 pixels."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"const shape = [1, 3, 640, 640];\n// Create a Float32Array to hold the pixel data of the image,\n// which should be preprocessed according to the model's specific needs.\nconst input = new Float32Array(1 * 3 * 640 * 640); // fill this array with your image data\n"})}),"\n",(0,t.jsx)(n.h3,{id:"performing-inference-1",children:"Performing inference"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"try {\n  // Perform the forward operation and receive the stylized image output.\n  const output = await executorchModule.forward(input, shape);\n  console.log('Stylization successful. Output Shape:', output.length);\n} catch (error) {\n  // Log any errors that occur during the forward pass.\n  console.error('Error during model execution:', error);\n}\n"})}),"\n",(0,t.jsx)(n.admonition,{type:"info",children:(0,t.jsx)(n.p,{children:"This code assumes that you have handled preprocessing of the input image (scaling, normalization) and postprocessing of the output (interpreting the raw output data) according to the model's requirements. Make sure to adjust these parts depending on your specific data and model outputs."})})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(l,{...e})}):l(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>d});var i=r(6540);const t={},o=i.createContext(t);function s(e){const n=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);