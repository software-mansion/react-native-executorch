"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[2092],{28453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>i});var o=t(96540);const r={},c=o.createContext(r);function s(e){const n=o.useContext(c);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),o.createElement(c.Provider,{value:n},e.children)}},84783:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>i,default:()=>h,frontMatter:()=>s,metadata:()=>o,toc:()=>l});const o=JSON.parse('{"id":"typescript-api/natural-language-processing/TextToSpeechModule","title":"TextToSpeechModule","description":"TypeScript API implementation of the useTextToSpeech hook.","source":"@site/docs/04-typescript-api/01-natural-language-processing/TextToSpeechModule.md","sourceDirName":"04-typescript-api/01-natural-language-processing","slug":"/typescript-api/natural-language-processing/TextToSpeechModule","permalink":"/react-native-executorch/docs/next/typescript-api/natural-language-processing/TextToSpeechModule","draft":false,"unlisted":false,"editUrl":"https://github.com/software-mansion/react-native-executorch/edit/main/docs/docs/04-typescript-api/01-natural-language-processing/TextToSpeechModule.md","tags":[],"version":"current","frontMatter":{"title":"TextToSpeechModule"},"sidebar":"tutorialSidebar","previous":{"title":"TextEmbeddingsModule","permalink":"/react-native-executorch/docs/next/typescript-api/natural-language-processing/TextEmbeddingsModule"},"next":{"title":"TokenizerModule","permalink":"/react-native-executorch/docs/next/typescript-api/natural-language-processing/TokenizerModule"}}');var r=t(74848),c=t(28453);const s={title:"TextToSpeechModule"},i=void 0,a={},l=[{value:"API Reference",id:"api-reference",level:2},{value:"High Level Overview",id:"high-level-overview",level:2},{value:"Methods",id:"methods",level:3},{value:"Loading the model",id:"loading-the-model",level:2},{value:"Running the model",id:"running-the-model",level:2},{value:"Example",id:"example",level:2},{value:"Speech Synthesis",id:"speech-synthesis",level:3},{value:"Streaming Synthesis",id:"streaming-synthesis",level:3}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,c.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(n.p,{children:["TypeScript API implementation of the ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/hooks/natural-language-processing/useTextToSpeech",children:"useTextToSpeech"})," hook."]}),"\n",(0,r.jsx)(n.h2,{id:"api-reference",children:"API Reference"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["For detailed API Reference for ",(0,r.jsx)(n.code,{children:"TextToSpeechModule"})," see: ",(0,r.jsxs)(n.a,{href:"/react-native-executorch/docs/next/api-reference/classes/TextToSpeechModule",children:[(0,r.jsx)(n.code,{children:"TextToSpeechModule"})," API Reference"]}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["For all text to speech models available out-of-the-box in React Native ExecuTorch see: ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/#models---text-to-speech",children:"TTS Models"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["For all supported voices in ",(0,r.jsx)(n.code,{children:"TextToSpeechModule"})," please refer to: ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/#tts-supported-voices",children:"Supported Voices"})]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"high-level-overview",children:"High Level Overview"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"import {\n  TextToSpeechModule,\n  KOKORO_MEDIUM,\n  KOKORO_VOICE_AF_HEART,\n} from 'react-native-executorch';\n\nconst model = new TextToSpeechModule();\nawait model.load(\n  {\n    model: KOKORO_MEDIUM,\n    voice: KOKORO_VOICE_AF_HEART,\n  },\n  (progress) => {\n    console.log(progress);\n  }\n);\n\nawait model.forward(text, 1.0);\n"})}),"\n",(0,r.jsx)(n.h3,{id:"methods",children:"Methods"}),"\n",(0,r.jsxs)(n.p,{children:["All methods of ",(0,r.jsx)(n.code,{children:"TextToSpeechModule"})," are explained in details here: ",(0,r.jsxs)(n.a,{href:"/react-native-executorch/docs/next/api-reference/classes/TextToSpeechModule",children:[(0,r.jsx)(n.code,{children:"TextToSpeechModule"})," API Reference"]})]}),"\n",(0,r.jsx)(n.h2,{id:"loading-the-model",children:"Loading the model"}),"\n",(0,r.jsxs)(n.p,{children:["To initialize the module, create an instance and call the ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/classes/TextToSpeechModule#load",children:(0,r.jsx)(n.code,{children:"load"})})," method with the following parameters:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/classes/TextToSpeechModule#config",children:(0,r.jsx)(n.code,{children:"config"})})," - Object containing:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/TextToSpeechConfig#model",children:(0,r.jsx)(n.code,{children:"model"})})," - Model configuration."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/TextToSpeechConfig#voice",children:(0,r.jsx)(n.code,{children:"voice"})})," - Voice configuration."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/classes/TextToSpeechModule#ondownloadprogresscallback",children:(0,r.jsx)(n.code,{children:"onDownloadProgressCallback"})})," - Callback to track download progress."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"This method returns a promise that resolves once the assets are downloaded and loaded into memory."}),"\n",(0,r.jsxs)(n.p,{children:["For more information on resource sources, see ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/fundamentals/loading-models",children:"loading models"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"running-the-model",children:"Running the model"}),"\n",(0,r.jsx)(n.p,{children:"The module provides two ways to generate speech:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/classes/TextToSpeechModule#forward",children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"forward(text, speed)"})})}),": Generates the complete audio waveform at once. Returns a promise resolving to a ",(0,r.jsx)(n.code,{children:"Float32Array"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsx)(n.p,{children:"Since it processes the entire text at once, it might take a significant amount of time to produce an audio for long text inputs."})}),"\n",(0,r.jsxs)(n.ol,{start:"2",children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/classes/TextToSpeechModule#stream",children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"stream({ text, speed })"})})}),': An async generator that yields chunks of audio as they are computed. This is ideal for reducing the "time to first audio" for long sentences.']}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"example",children:"Example"}),"\n",(0,r.jsx)(n.h3,{id:"speech-synthesis",children:"Speech Synthesis"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"import {\n  TextToSpeechModule,\n  KOKORO_MEDIUM,\n  KOKORO_VOICE_AF_HEART,\n} from 'react-native-executorch';\nimport { AudioContext } from 'react-native-audio-api';\n\nconst tts = new TextToSpeechModule();\nconst audioContext = new AudioContext({ sampleRate: 24000 });\n\ntry {\n  await tts.load({\n    model: KOKORO_MEDIUM,\n    voice: KOKORO_VOICE_AF_HEART,\n  });\n\n  const waveform = await tts.forward('Hello from ExecuTorch!', 1.0);\n\n  // Create audio buffer and play\n  const audioBuffer = audioContext.createBuffer(1, waveform.length, 24000);\n  audioBuffer.getChannelData(0).set(waveform);\n\n  const source = audioContext.createBufferSource();\n  source.buffer = audioBuffer;\n  source.connect(audioContext.destination);\n  source.start();\n} catch (error) {\n  console.error('Text-to-speech failed:', error);\n}\n"})}),"\n",(0,r.jsx)(n.h3,{id:"streaming-synthesis",children:"Streaming Synthesis"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"import {\n  TextToSpeechModule,\n  KOKORO_MEDIUM,\n  KOKORO_VOICE_AF_HEART,\n} from 'react-native-executorch';\nimport { AudioContext } from 'react-native-audio-api';\n\nconst tts = new TextToSpeechModule();\nconst audioContext = new AudioContext({ sampleRate: 24000 });\n\nawait tts.load({ model: KOKORO_MEDIUM, voice: KOKORO_VOICE_AF_HEART });\n\ntry {\n  for await (const chunk of tts.stream({\n    text: 'This is a streaming test, with a sample input.',\n    speed: 1.0,\n  })) {\n    // Play each chunk sequentially\n    await new Promise<void>((resolve) => {\n      const audioBuffer = audioContext.createBuffer(1, chunk.length, 24000);\n      audioBuffer.getChannelData(0).set(chunk);\n\n      const source = audioContext.createBufferSource();\n      source.buffer = audioBuffer;\n      source.connect(audioContext.destination);\n      source.onEnded = () => resolve();\n      source.start();\n    });\n  }\n} catch (error) {\n  console.error('Streaming failed:', error);\n}\n"})})]})}function h(e={}){const{wrapper:n}={...(0,c.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);