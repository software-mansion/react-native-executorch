"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[181],{28453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>s});var i=t(96540);const a={},r=i.createContext(a);function o(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),i.createElement(r.Provider,{value:n},e.children)}},33359:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"hooks/computer-vision/useImageSegmentation","title":"useImageSegmentation","description":"Semantic image segmentation, akin to image classification, tries to assign the content of the image to one of the predefined classes. However, in case of segmentation this classification is done on a per-pixel basis, so as the result the model provides an image-sized array of scores for each of the classes. You can then use this information to detect objects on a per-pixel basis. React Native ExecuTorch offers a dedicated hook useImageSegmentation for this task.","source":"@site/docs/03-hooks/02-computer-vision/useImageSegmentation.md","sourceDirName":"03-hooks/02-computer-vision","slug":"/hooks/computer-vision/useImageSegmentation","permalink":"/react-native-executorch/docs/next/hooks/computer-vision/useImageSegmentation","draft":false,"unlisted":false,"editUrl":"https://github.com/software-mansion/react-native-executorch/edit/main/docs/docs/03-hooks/02-computer-vision/useImageSegmentation.md","tags":[],"version":"current","frontMatter":{"title":"useImageSegmentation"},"sidebar":"tutorialSidebar","previous":{"title":"useImageEmbeddings","permalink":"/react-native-executorch/docs/next/hooks/computer-vision/useImageEmbeddings"},"next":{"title":"useOCR","permalink":"/react-native-executorch/docs/next/hooks/computer-vision/useOCR"}}');var a=t(74848),r=t(28453);const o={title:"useImageSegmentation"},s=void 0,c={},l=[{value:"API Reference",id:"api-reference",level:2},{value:"High Level Overview",id:"high-level-overview",level:2},{value:"Arguments",id:"arguments",level:3},{value:"Returns",id:"returns",level:3},{value:"Running the model",id:"running-the-model",level:2},{value:"Example",id:"example",level:2},{value:"Supported models",id:"supported-models",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(n.p,{children:["Semantic image segmentation, akin to image classification, tries to assign the content of the image to one of the predefined classes. However, in case of segmentation this classification is done on a per-pixel basis, so as the result the model provides an image-sized array of scores for each of the classes. You can then use this information to detect objects on a per-pixel basis. React Native ExecuTorch offers a dedicated hook ",(0,a.jsx)(n.code,{children:"useImageSegmentation"})," for this task."]}),"\n",(0,a.jsx)(n.admonition,{type:"warning",children:(0,a.jsxs)(n.p,{children:["It is recommended to use models provided by us which are available at our ",(0,a.jsx)(n.a,{href:"https://huggingface.co/collections/software-mansion/image-segmentation-68d5291bdf4a30bee0220f4f",children:"Hugging Face repository"}),", you can also use ",(0,a.jsx)(n.a,{href:"https://github.com/software-mansion/react-native-executorch/blob/main/packages/react-native-executorch/src/constants/modelUrls.ts",children:"constants"})," shipped with our library."]})}),"\n",(0,a.jsx)(n.h2,{id:"api-reference",children:"API Reference"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["For detailed API Reference for ",(0,a.jsx)(n.code,{children:"useImageSegmentation"})," see: ",(0,a.jsxs)(n.a,{href:"/react-native-executorch/docs/next/api-reference/functions/useImageSegmentation",children:[(0,a.jsx)(n.code,{children:"useImageSegmentation"})," API Reference"]}),"."]}),"\n",(0,a.jsxs)(n.li,{children:["For all image segmentation models available out-of-the-box in React Native ExecuTorch see: ",(0,a.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/#models---image-segmentation",children:"Image Segmentation Models"}),"."]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"high-level-overview",children:"High Level Overview"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"import {\n  useImageSegmentation,\n  DEEPLAB_V3_RESNET50,\n} from 'react-native-executorch';\n\nconst model = useImageSegmentation({ model: DEEPLAB_V3_RESNET50 });\n\nconst imageUri = 'file::///Users/.../cute_cat.png';\n\ntry {\n  const outputDict = await model.forward(imageUri);\n} catch (error) {\n  console.error(error);\n}\n"})}),"\n",(0,a.jsx)(n.h3,{id:"arguments",children:"Arguments"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"useImageSegmentation"})," takes ",(0,a.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/ImageSegmentationProps",children:(0,a.jsx)(n.code,{children:"ImageSegmentationProps"})})," that consists of:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"model"})," containing ",(0,a.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/ImageSegmentationProps#modelsource",children:(0,a.jsx)(n.code,{children:"modelSource"})}),"."]}),"\n",(0,a.jsxs)(n.li,{children:["An optional flag ",(0,a.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/ImageSegmentationProps#preventload",children:(0,a.jsx)(n.code,{children:"preventLoad"})})," which prevents auto-loading of the model."]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"You need more details? Check the following resources:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["For detailed information about ",(0,a.jsx)(n.code,{children:"useImageSegmentation"})," arguments check this section: ",(0,a.jsxs)(n.a,{href:"/react-native-executorch/docs/next/api-reference/functions/useImageSegmentation#parameters",children:[(0,a.jsx)(n.code,{children:"useImageSegmentation"})," arguments"]}),"."]}),"\n",(0,a.jsxs)(n.li,{children:["For all image segmentation models available out-of-the-box in React Native ExecuTorch see: ",(0,a.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/#models---image-segmentation",children:"Image Segmentation Models"}),"."]}),"\n",(0,a.jsxs)(n.li,{children:["For more information on loading resources, take a look at ",(0,a.jsx)(n.a,{href:"/react-native-executorch/docs/next/fundamentals/loading-models",children:"loading models"})," page."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"returns",children:"Returns"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"useImageSegmentation"})," returns an object called ",(0,a.jsx)(n.code,{children:"ImageSegmentationType"})," containing bunch of functions to interact with image segmentation models. To get more details please read: ",(0,a.jsxs)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/ImageSegmentationType",children:[(0,a.jsx)(n.code,{children:"ImageSegmentationType"})," API Reference"]}),"."]}),"\n",(0,a.jsx)(n.h2,{id:"running-the-model",children:"Running the model"}),"\n",(0,a.jsxs)(n.p,{children:["To run the model, you can use the ",(0,a.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/ImageSegmentationType#forward",children:(0,a.jsx)(n.code,{children:"forward"})})," method. It accepts three arguments: a required image, an optional list of classes, and an optional flag whether to resize the output to the original dimensions."]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"The image can be a remote URL, a local file URI, or a base64-encoded image."}),"\n",(0,a.jsxs)(n.li,{children:["The ",(0,a.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/ImageSegmentationType#classesofinterest",children:(0,a.jsx)(n.code,{children:"classesOfInterest"})})," list contains classes for which to output the full results. By default the list is empty, and only the most probable classes are returned (essentially an arg max for each pixel). Look at ",(0,a.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/enumerations/DeeplabLabel",children:(0,a.jsx)(n.code,{children:"DeeplabLabel"})})," enum for possible classes."]}),"\n",(0,a.jsxs)(n.li,{children:["The ",(0,a.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/ImageSegmentationType#resize",children:(0,a.jsx)(n.code,{children:"resize"})})," flag says whether the output will be rescaled back to the size of the image you put in. The default is ",(0,a.jsx)(n.code,{children:"false"}),". The model runs inference on a scaled (probably smaller) version of your image (224x224 for ",(0,a.jsx)(n.code,{children:"DEEPLAB_V3_RESNET50"}),"). If you choose to resize, the output will be ",(0,a.jsx)(n.code,{children:"number[]"})," of size ",(0,a.jsx)(n.code,{children:"width * height"})," of your original image."]}),"\n"]}),"\n",(0,a.jsx)(n.admonition,{type:"warning",children:(0,a.jsxs)(n.p,{children:["Setting ",(0,a.jsx)(n.code,{children:"resize"})," to true will make ",(0,a.jsx)(n.code,{children:"forward"})," slower."]})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/ImageSegmentationType#forward",children:(0,a.jsx)(n.code,{children:"forward"})})," returns a promise which can resolve either to an error or a dictionary containing number arrays with size depending on ",(0,a.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/ImageSegmentationType#resize",children:(0,a.jsx)(n.code,{children:"resize"})}),":"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["For the key ",(0,a.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/enumerations/DeeplabLabel#argmax",children:(0,a.jsx)(n.code,{children:"DeeplabLabel.ARGMAX"})})," the array contains for each pixel an integer corresponding to the class with the highest probability."]}),"\n",(0,a.jsxs)(n.li,{children:["For every other key from ",(0,a.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/enumerations/DeeplabLabel",children:(0,a.jsx)(n.code,{children:"DeeplabLabel"})}),", if the label was included in ",(0,a.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/ImageSegmentationType#classesofinterest",children:(0,a.jsx)(n.code,{children:"classesOfInterest"})})," the dictionary will contain an array of floats corresponding to the probability of this class for every pixel."]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"example",children:"Example"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"function App() {\n  const model = useImageSegmentation({ model: DEEPLAB_V3_RESNET50 });\n\n  // ...\n  const imageUri = 'file::///Users/.../cute_cat.png';\n\n  try {\n    const outputDict = await model.forward(imageUri, [DeeplabLabel.CAT], true);\n  } catch (error) {\n    console.error(error);\n  }\n  // ...\n}\n"})}),"\n",(0,a.jsx)(n.h2,{id:"supported-models",children:"Supported models"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Model"}),(0,a.jsx)(n.th,{children:"Number of classes"}),(0,a.jsx)(n.th,{children:"Class list"})]})}),(0,a.jsx)(n.tbody,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.a,{href:"https://huggingface.co/software-mansion/react-native-executorch-deeplab-v3",children:"deeplabv3_resnet50"})}),(0,a.jsx)(n.td,{children:"21"}),(0,a.jsx)(n.td,{children:(0,a.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/enumerations/DeeplabLabel",children:"DeeplabLabel"})})]})})]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}}}]);