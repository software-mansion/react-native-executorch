"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[58913],{28453:(e,c,r)=>{r.d(c,{R:()=>i,x:()=>a});var n=r(96540);const t={},o=n.createContext(t);function i(e){const c=n.useContext(o);return n.useMemo(function(){return"function"==typeof e?e(c):{...c,...e}},[c,e])}function a(e){let c;return c=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),n.createElement(o.Provider,{value:c},e.children)}},98379:(e,c,r)=>{r.r(c),r.d(c,{assets:()=>s,contentTitle:()=>a,default:()=>h,frontMatter:()=>i,metadata:()=>n,toc:()=>l});const n=JSON.parse('{"id":"typescript-api/computer-vision/VerticalOCRModule","title":"VerticalOCRModule","description":"TypeScript API implementation of the useVerticalOCR hook.","source":"@site/docs/04-typescript-api/02-computer-vision/VerticalOCRModule.md","sourceDirName":"04-typescript-api/02-computer-vision","slug":"/typescript-api/computer-vision/VerticalOCRModule","permalink":"/react-native-executorch/docs/next/typescript-api/computer-vision/VerticalOCRModule","draft":false,"unlisted":false,"editUrl":"https://github.com/software-mansion/react-native-executorch/edit/main/docs/docs/04-typescript-api/02-computer-vision/VerticalOCRModule.md","tags":[],"version":"current","frontMatter":{"title":"VerticalOCRModule"},"sidebar":"tutorialSidebar","previous":{"title":"TextToImageModule","permalink":"/react-native-executorch/docs/next/typescript-api/computer-vision/TextToImageModule"},"next":{"title":"ExecuTorch Bindings","permalink":"/react-native-executorch/docs/next/category/executorch-bindings-1"}}');var t=r(74848),o=r(28453);const i={title:"VerticalOCRModule"},a=void 0,s={},l=[{value:"API Reference",id:"api-reference",level:2},{value:"High Level Overview",id:"high-level-overview",level:2},{value:"Methods",id:"methods",level:3},{value:"Loading the model",id:"loading-the-model",level:2},{value:"Running the model",id:"running-the-model",level:2}];function d(e){const c={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(c.p,{children:["TypeScript API implementation of the ",(0,t.jsx)(c.a,{href:"/react-native-executorch/docs/next/hooks/computer-vision/useVerticalOCR",children:"useVerticalOCR"})," hook."]}),"\n",(0,t.jsx)(c.h2,{id:"api-reference",children:"API Reference"}),"\n",(0,t.jsxs)(c.ul,{children:["\n",(0,t.jsxs)(c.li,{children:["For detailed API Reference for ",(0,t.jsx)(c.code,{children:"VerticalOCRModule"})," see: ",(0,t.jsxs)(c.a,{href:"/react-native-executorch/docs/next/api-reference/classes/VerticalOCRModule",children:[(0,t.jsx)(c.code,{children:"VerticalOCRModule"})," API Reference"]}),"."]}),"\n",(0,t.jsxs)(c.li,{children:["For all alphabets available in ocr out-of-the-box in React Native ExecuTorch see: ",(0,t.jsx)(c.a,{href:"/react-native-executorch/docs/next/api-reference/#ocr-supported-alphabets",children:"OCR Supported Alphabets"}),"."]}),"\n"]}),"\n",(0,t.jsx)(c.h2,{id:"high-level-overview",children:"High Level Overview"}),"\n",(0,t.jsx)(c.pre,{children:(0,t.jsx)(c.code,{className:"language-typescript",children:"import { VerticalOCRModule, OCR_ENGLISH } from 'react-native-executorch';\n\nconst imageUri = 'path/to/image.png';\n\n// Creating an instance\nconst verticalOCRModule = new VerticalOCRModule();\n\n// Loading the model\nawait verticalOCRModule.load(OCR_ENGLISH);\n\n// Running the model\nconst detections = await verticalOCRModule.forward(imageUri);\n"})}),"\n",(0,t.jsx)(c.h3,{id:"methods",children:"Methods"}),"\n",(0,t.jsxs)(c.p,{children:["All methods of ",(0,t.jsx)(c.code,{children:"VerticalOCRModule"})," are explained in details here: ",(0,t.jsxs)(c.a,{href:"/react-native-executorch/docs/next/api-reference/classes/VerticalOCRModule",children:[(0,t.jsx)(c.code,{children:"VerticalOCRModule"})," API Reference"]})]}),"\n",(0,t.jsx)(c.h2,{id:"loading-the-model",children:"Loading the model"}),"\n",(0,t.jsxs)(c.p,{children:["To load the model, use the ",(0,t.jsx)(c.a,{href:"/react-native-executorch/docs/next/api-reference/classes/VerticalOCRModule#load",children:(0,t.jsx)(c.code,{children:"load"})})," method. It accepts an object:"]}),"\n",(0,t.jsxs)(c.ul,{children:["\n",(0,t.jsxs)(c.li,{children:["\n",(0,t.jsxs)(c.p,{children:[(0,t.jsx)(c.a,{href:"/react-native-executorch/docs/next/api-reference/classes/VerticalOCRModule#model",children:(0,t.jsx)(c.code,{children:"model"})})," - Object containing:"]}),"\n",(0,t.jsxs)(c.ul,{children:["\n",(0,t.jsxs)(c.li,{children:[(0,t.jsx)(c.a,{href:"/react-native-executorch/docs/next/api-reference/classes/VerticalOCRModule#detectorsource",children:(0,t.jsx)(c.code,{children:"detectorSource"})})," - Location of the used detector."]}),"\n",(0,t.jsxs)(c.li,{children:[(0,t.jsx)(c.a,{href:"/react-native-executorch/docs/next/api-reference/classes/VerticalOCRModule#recognizersource",children:(0,t.jsx)(c.code,{children:"recognizerSource"})})," - Location of the used recognizer."]}),"\n",(0,t.jsxs)(c.li,{children:[(0,t.jsx)(c.a,{href:"/react-native-executorch/docs/next/api-reference/classes/VerticalOCRModule#recognizersource",children:(0,t.jsx)(c.code,{children:"language"})})," - Language used in OCR."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(c.li,{children:["\n",(0,t.jsxs)(c.p,{children:[(0,t.jsx)(c.a,{href:"/react-native-executorch/docs/next/api-reference/classes/VerticalOCRModule#independentcharacters",children:(0,t.jsx)(c.code,{children:"independentCharacters"})})," - Flag indicating to either treat characters as independent or not."]}),"\n"]}),"\n",(0,t.jsxs)(c.li,{children:["\n",(0,t.jsxs)(c.p,{children:[(0,t.jsx)(c.a,{href:"/react-native-executorch/docs/next/api-reference/classes/VerticalOCRModule#ondownloadprogresscallback",children:(0,t.jsx)(c.code,{children:"onDownloadProgressCallback"})})," - Callback to track download progress."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(c.p,{children:"This method returns a promise, which can resolve to an error or void."}),"\n",(0,t.jsxs)(c.p,{children:["For more information on loading resources, take a look at ",(0,t.jsx)(c.a,{href:"/react-native-executorch/docs/next/fundamentals/loading-models",children:"loading models"})," page."]}),"\n",(0,t.jsx)(c.h2,{id:"running-the-model",children:"Running the model"}),"\n",(0,t.jsxs)(c.p,{children:["To run the model, you can use the ",(0,t.jsx)(c.a,{href:"/react-native-executorch/docs/next/api-reference/classes/VerticalOCRModule#forward",children:(0,t.jsx)(c.code,{children:"forward"})})," method. It accepts one argument, which is the image. The image can be a remote URL, a local file URI, or a base64-encoded image. The method returns a promise, which can resolve either to an error or an array of ",(0,t.jsx)(c.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/OCRDetection",children:(0,t.jsx)(c.code,{children:"OCRDetection"})})," objects. Each object contains coordinates of the bounding box, the label of the detected object, and the confidence score."]})]})}function h(e={}){const{wrapper:c}={...(0,o.R)(),...e.components};return c?(0,t.jsx)(c,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}}}]);