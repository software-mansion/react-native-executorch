"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4108],{4483:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>s,metadata:()=>n,toc:()=>d});const n=JSON.parse('{"id":"typescript-api/ImageSegmentationModule","title":"ImageSegmentationModule","description":"TypeScript API implementation of the useImageSegmentation hook.","source":"@site/versioned_docs/version-0.4.x/typescript-api/ImageSegmentationModule.md","sourceDirName":"typescript-api","slug":"/typescript-api/ImageSegmentationModule","permalink":"/react-native-executorch/docs/0.4.x/typescript-api/ImageSegmentationModule","draft":false,"unlisted":false,"editUrl":"https://github.com/software-mansion/react-native-executorch/edit/main/docs/versioned_docs/version-0.4.x/typescript-api/ImageSegmentationModule.md","tags":[],"version":"0.4.x","frontMatter":{"title":"ImageSegmentationModule"},"sidebar":"tutorialSidebar","previous":{"title":"VerticalOCRModule","permalink":"/react-native-executorch/docs/0.4.x/typescript-api/VerticalOCRModule"},"next":{"title":"ClassificationModule","permalink":"/react-native-executorch/docs/0.4.x/typescript-api/ClassificationModule"}}');var i=o(4848),r=o(8453);const s={title:"ImageSegmentationModule"},a=void 0,l={},d=[{value:"Reference",id:"reference",level:2},{value:"Methods",id:"methods",level:3},{value:"Loading the model",id:"loading-the-model",level:2},{value:"Running the model",id:"running-the-model",level:2}];function c(e){const t={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components},{Details:o}=t;return o||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(t.p,{children:["TypeScript API implementation of the ",(0,i.jsx)(t.a,{href:"/react-native-executorch/docs/0.4.x/computer-vision/useImageSegmentation",children:"useImageSegmentation"})," hook."]}),"\n",(0,i.jsx)(t.h2,{id:"reference",children:"Reference"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-typescript",children:"import {\n  ImageSegmentationModule,\n  DEEPLAB_V3_RESNET50,\n} from 'react-native-executorch';\n\nconst imageUri = 'path/to/image.png';\n\n// Loading the model\nawait ImageSegmentationModule.load(DEEPLAB_V3_RESNET50);\n\n// Running the model\nconst outputDict = await ImageSegmentationModule.forward(imageUri);\n"})}),"\n",(0,i.jsx)(t.h3,{id:"methods",children:"Methods"}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{children:"Method"}),(0,i.jsx)(t.th,{children:"Type"}),(0,i.jsx)(t.th,{children:"Description"})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"load"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"(modelSource: ResourceSource): Promise<void>"})}),(0,i.jsxs)(t.td,{children:["Loads the model, where ",(0,i.jsx)(t.code,{children:"modelSource"})," is a string that specifies the location of the model binary."]})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"forward"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"(input: string, classesOfInterest?: DeeplabLabel[], resize?: boolean) => Promise<{[key in DeeplabLabel]?: number[]}>"})}),(0,i.jsxs)(t.td,{children:["Executes the model's forward pass, where : ",(0,i.jsx)("br",{})," * ",(0,i.jsx)(t.code,{children:"input"})," can be a fetchable resource or a Base64-encoded string. ",(0,i.jsx)("br",{})," * ",(0,i.jsx)(t.code,{children:"classesOfInterest"})," is an optional list of ",(0,i.jsx)(t.code,{children:"DeeplabLabel"}),' used to indicate additional arrays of probabilities to output (see section "Running the model"). The default is an empty list. ',(0,i.jsx)("br",{})," * ",(0,i.jsx)(t.code,{children:"resize"}),' is an optional boolean to indicate whether the output should be resized to the original image dimensions, or left in the size of the model (see section "Running the model"). The default is ',(0,i.jsx)(t.code,{children:"false"}),". ",(0,i.jsx)("br",{})," ",(0,i.jsx)("br",{})," The return is a dictionary containing: ",(0,i.jsx)("br",{})," * for the key ",(0,i.jsx)(t.code,{children:"DeeplabLabel.ARGMAX"})," an array of integers corresponding to the most probable class for each pixel ",(0,i.jsx)("br",{})," * an array of floats for each class from ",(0,i.jsx)(t.code,{children:"classesOfInterest"})," corresponding to the probabilities for this class."]})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"onDownloadProgress"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"(callback: (downloadProgress: number) => void): any"})}),(0,i.jsx)(t.td,{children:"Subscribe to the download progress event."})]})]})]}),"\n",(0,i.jsxs)(o,{children:[(0,i.jsx)("summary",{children:"Type definitions"}),(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-typescript",children:"type ResourceSource = string | number | object;\n"})})]}),"\n",(0,i.jsx)(t.h2,{id:"loading-the-model",children:"Loading the model"}),"\n",(0,i.jsxs)(t.p,{children:["To load the model, use the ",(0,i.jsx)(t.code,{children:"load"})," method. It accepts the ",(0,i.jsx)(t.code,{children:"modelSource"})," which is a string that specifies the location of the model binary. For more information, take a look at ",(0,i.jsx)(t.a,{href:"/react-native-executorch/docs/0.4.x/fundamentals/loading-models",children:"loading models"})," page. This method returns a promise, which can resolve to an error or void."]}),"\n",(0,i.jsx)(t.h2,{id:"running-the-model",children:"Running the model"}),"\n",(0,i.jsxs)(t.p,{children:["To run the model, you can use the ",(0,i.jsx)(t.code,{children:"forward"})," method. It accepts three arguments: a required image, an optional list of classes, and an optional flag whether to resize the output to the original dimensions."]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"The image can be a remote URL, a local file URI, or a base64-encoded image."}),"\n",(0,i.jsxs)(t.li,{children:["The ",(0,i.jsx)(t.code,{children:"classesOfInterest"})," list contains classes for which to output the full results. By default the list is empty, and only the most probable classes are returned (essentially an arg max for each pixel). Look at ",(0,i.jsx)(t.code,{children:"DeeplabLabel"})," enum for possible classes."]}),"\n",(0,i.jsxs)(t.li,{children:["The ",(0,i.jsx)(t.code,{children:"resize"})," flag says whether the output will be rescaled back to the size of the image you put in. The default is ",(0,i.jsx)(t.code,{children:"false"}),". The model runs inference on a scaled (probably smaller) version of your image (224x224 for the ",(0,i.jsx)(t.code,{children:"DEEPLAB_V3_RESNET50"}),"). If you choose to resize, the output will be ",(0,i.jsx)(t.code,{children:"number[]"})," of size ",(0,i.jsx)(t.code,{children:"width * height"})," of your original image."]}),"\n"]}),"\n",(0,i.jsx)(t.admonition,{type:"caution",children:(0,i.jsxs)(t.p,{children:["Setting ",(0,i.jsx)(t.code,{children:"resize"})," to true will make ",(0,i.jsx)(t.code,{children:"forward"})," slower."]})}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.code,{children:"forward"})," returns a promise which can resolve either to an error or a dictionary containing number arrays with size depending on ",(0,i.jsx)(t.code,{children:"resize"}),":"]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["For the key ",(0,i.jsx)(t.code,{children:"DeeplabLabel.ARGMAX"})," the array contains for each pixel an integer corresponding to the class with the highest probability."]}),"\n",(0,i.jsxs)(t.li,{children:["For every other key from ",(0,i.jsx)(t.code,{children:"DeeplabLabel"}),", if the label was included in ",(0,i.jsx)(t.code,{children:"classesOfInterest"})," the dictionary will contain an array of floats corresponding to the probability of this class for every pixel."]}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453:(e,t,o)=>{o.d(t,{R:()=>s,x:()=>a});var n=o(6540);const i={},r=n.createContext(i);function s(e){const t=n.useContext(r);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),n.createElement(r.Provider,{value:t},e.children)}}}]);