"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[25],{5680:(e,t,r)=>{r.d(t,{xA:()=>u,yg:()=>g});var n=r(6540);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function o(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?o(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function l(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},o=Object.keys(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var s=n.createContext({}),c=function(e){var t=n.useContext(s),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},u=function(e){var t=c(e.components);return n.createElement(s.Provider,{value:t},e.children)},p="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),p=c(r),d=a,g=p["".concat(s,".").concat(d)]||p[d]||m[d]||o;return r?n.createElement(g,i(i({ref:t},u),{},{components:r})):n.createElement(g,i({ref:t},u))}));function g(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=r.length,i=new Array(o);i[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[p]="string"==typeof e?e:a,i[1]=l;for(var c=2;c<o;c++)i[c]=r[c];return n.createElement.apply(null,i)}return n.createElement.apply(null,r)}d.displayName="MDXCreateElement"},950:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>m,frontMatter:()=>o,metadata:()=>l,toc:()=>c});var n=r(8168),a=(r(6540),r(5680));const o={title:"useStyleTransfer",sidebar_position:3},i=void 0,l={unversionedId:"computer-vision/useStyleTransfer",id:"computer-vision/useStyleTransfer",title:"useStyleTransfer",description:"Style transfer is a technique used in computer graphics and machine learning where the visual style of one image is applied to the content of another. This is achieved using algorithms that manipulate data from both images, typically with the aid of a neural network. The result is a new image that combines the artistic elements of one picture with the structural details of another, effectively merging art with traditional imagery. React Native ExecuTorch offers a dedicated hook useStyleTransfer, for this task. However before you start you'll need to obtain ExecuTorch-compatible model binary.",source:"@site/docs/computer-vision/useStyleTransfer.mdx",sourceDirName:"computer-vision",slug:"/computer-vision/useStyleTransfer",permalink:"/react-native-executorch/docs/computer-vision/useStyleTransfer",draft:!1,editUrl:"https://github.com/software-mansion/react-native-executorch/edit/main/docs/docs/computer-vision/useStyleTransfer.mdx",tags:[],version:"current",sidebarPosition:3,frontMatter:{title:"useStyleTransfer",sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"useObjectDetection",permalink:"/react-native-executorch/docs/computer-vision/useObjectDetection"},next:{title:"Module API",permalink:"/react-native-executorch/docs/category/module-api"}},s={},c=[{value:"Reference",id:"reference",level:2},{value:"Arguments",id:"arguments",level:3},{value:"Returns",id:"returns",level:3},{value:"Running the model",id:"running-the-model",level:2},{value:"Example",id:"example",level:2},{value:"Supported Models",id:"supported-models",level:2}],u={toc:c},p="wrapper";function m(e){let{components:t,...r}=e;return(0,a.yg)(p,(0,n.A)({},u,r,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Style transfer is a technique used in computer graphics and machine learning where the visual style of one image is applied to the content of another. This is achieved using algorithms that manipulate data from both images, typically with the aid of a neural network. The result is a new image that combines the artistic elements of one picture with the structural details of another, effectively merging art with traditional imagery. React Native ExecuTorch offers a dedicated hook ",(0,a.yg)("inlineCode",{parentName:"p"},"useStyleTransfer"),", for this task. However before you start you'll need to obtain ExecuTorch-compatible model binary."),(0,a.yg)("admonition",{type:"caution"},(0,a.yg)("p",{parentName:"admonition"},"It is recommended to use models provided by us which are available at our ",(0,a.yg)("a",{parentName:"p",href:"https://huggingface.co/software-mansion/react-native-executorch-style-transfer-candy"},"HuggingFace repository"),", you can also use ",(0,a.yg)("a",{parentName:"p",href:"https://github.com/software-mansion/react-native-executorch/tree/main/src/constants/modelUrls.ts"},"constants")," shipped with our library")),(0,a.yg)("h2",{id:"reference"},"Reference"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-typescript"},"import {\n  useStyleTransfer,\n  STYLE_TRANSFER_CANDY,\n} from 'react-native-executorch';\n\nconst model = useStyleTransfer({\n  modelSource: STYLE_TRANSFER_CANDY,\n});\n\nconst imageUri = 'file::///Users/.../cute_cat.png';\n\ntry {\n  const generatedImageUrl = await model.forward(imageUri);\n} catch (error) {\n  console.error(error);\n}\n")),(0,a.yg)("details",null,(0,a.yg)("summary",null,"Type definitions"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-typescript"},"interface StyleTransferModule {\n  error: string | null;\n  isReady: boolean;\n  isGenerating: boolean;\n  forward: (input: string) => Promise<string>;\n}\n"))),(0,a.yg)("h3",{id:"arguments"},"Arguments"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},(0,a.yg)("inlineCode",{parentName:"strong"},"modelSource")),"\nA string that specifies the location of the model binary. For more information, take a look at ",(0,a.yg)("a",{parentName:"p",href:"/react-native-executorch/docs/fundamentals/loading-models"},"loading models")," page."),(0,a.yg)("h3",{id:"returns"},"Returns"),(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"Field"),(0,a.yg)("th",{parentName:"tr",align:null},"Type"),(0,a.yg)("th",{parentName:"tr",align:null},"Description"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("inlineCode",{parentName:"td"},"forward")),(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("inlineCode",{parentName:"td"},"(input: string) => Promise<string>")),(0,a.yg)("td",{parentName:"tr",align:null},"Executes the model's forward pass, where ",(0,a.yg)("inlineCode",{parentName:"td"},"input")," can be a fetchable resource or a Base64-encoded string.")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("inlineCode",{parentName:"td"},"error")),(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("code",null,"string ","|"," null")),(0,a.yg)("td",{parentName:"tr",align:null},"Contains the error message if the model failed to load.")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("inlineCode",{parentName:"td"},"isGenerating")),(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("inlineCode",{parentName:"td"},"boolean")),(0,a.yg)("td",{parentName:"tr",align:null},"Indicates whether the model is currently processing an inference.")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("inlineCode",{parentName:"td"},"isReady")),(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("inlineCode",{parentName:"td"},"boolean")),(0,a.yg)("td",{parentName:"tr",align:null},"Indicates whether the model has successfully loaded and is ready for inference.")))),(0,a.yg)("h2",{id:"running-the-model"},"Running the model"),(0,a.yg)("p",null,"To run the moel, you can use ",(0,a.yg)("inlineCode",{parentName:"p"},"forward")," method. It accepts one argument, which is the image. The image can be a remote URL, a local file URI, or a base64-encoded image. The function returns a promise which can resolve either to error or a URL to generated image."),(0,a.yg)("admonition",{type:"info"},(0,a.yg)("p",{parentName:"admonition"},"Images from external sources and the generated image are stored in your application's temporary directory.")),(0,a.yg)("h2",{id:"example"},"Example"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-typescript"},"function App(){\n  const model = useStyleTransfer(\n      modelSource: STYLE_TRANSFER_CANDY,\n  );\n\n  ...\n  const imageUri = 'file::///Users/.../cute_cat.png';\n\n  try{\n      const generatedImageUrl = await model.forward(imageUri)\n  }catch(error){\n      console.error(error)\n  }\n  ...\n}\n")),(0,a.yg)("h2",{id:"supported-models"},"Supported Models"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"https://github.com/pytorch/examples/tree/main/fast_neural_style"},"Candy")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"https://github.com/pytorch/examples/tree/main/fast_neural_style"},"Mosaic")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"https://github.com/pytorch/examples/tree/main/fast_neural_style"},"Udnie")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"https://github.com/pytorch/examples/tree/main/fast_neural_style"},"Rain princess"))))}m.isMDXComponent=!0}}]);