"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[1865],{2543:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>a,frontMatter:()=>d,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"hookless-api/LLMModule","title":"LLMModule","description":"Hookless implementation of the useLLM hook.","source":"@site/versioned_docs/version-0.3.x/hookless-api/LLMModule.md","sourceDirName":"hookless-api","slug":"/hookless-api/LLMModule","permalink":"/react-native-executorch/docs/0.3.x/hookless-api/LLMModule","draft":false,"unlisted":false,"editUrl":"https://github.com/software-mansion/react-native-executorch/edit/main/docs/versioned_docs/version-0.3.x/hookless-api/LLMModule.md","tags":[],"version":"0.3.x","sidebarPosition":3,"frontMatter":{"title":"LLMModule","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"ExecuTorchModule","permalink":"/react-native-executorch/docs/0.3.x/hookless-api/ExecutorchModule"},"next":{"title":"StyleTransferModule","permalink":"/react-native-executorch/docs/0.3.x/hookless-api/StyleTransferModule"}}');var r=o(4848),s=o(8453);const d={title:"LLMModule",sidebar_position:3},i=void 0,l={},c=[{value:"Reference",id:"reference",level:2},{value:"Methods",id:"methods",level:3},{value:"Loading the model",id:"loading-the-model",level:2},{value:"Listening for download progress",id:"listening-for-download-progress",level:2},{value:"Running the model",id:"running-the-model",level:2},{value:"Listening for token",id:"listening-for-token",level:2},{value:"Interrupting the model",id:"interrupting-the-model",level:2},{value:"Deleting the model from memory",id:"deleting-the-model-from-memory",level:2}];function h(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components},{Details:o}=n;return o||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(n.p,{children:["Hookless implementation of the ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/0.3.x/llms/useLLM",children:"useLLM"})," hook."]}),"\n",(0,r.jsx)(n.h2,{id:"reference",children:"Reference"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"import {\n  LLMModule,\n  LLAMA3_2_1B_QLORA,\n  LLAMA3_2_1B_TOKENIZER,\n} from 'react-native-executorch';\n\n// Listening for download progress\nLLMModule.onDownloadProgress((progress) => {\n  console.log(progress);\n});\n\n// Loading the model\nawait LLMModule.load(LLAMA3_2_1B_QLORA, LLAMA3_2_1B_TOKENIZER);\n\n// Listening for token\nLLMModule.onToken((token) => {\n  console.log(token);\n});\n\n// Running the model\nLLMModule.generate('Hello, World!');\n\n// Interrupting the model\nLLMModule.interrupt();\n\n// Deleting the model from memory\nLLMModule.delete();\n"})}),"\n",(0,r.jsx)(n.h3,{id:"methods",children:"Methods"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Method"}),(0,r.jsx)(n.th,{children:"Type"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"load"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"LLMModule.load(modelSource: ResourceSource, tokenizerSource: ResourceSource, systemPrompt?: string, messageHistory?: MessageType[], contextWindowLength?: number): Promise<void>"})}),(0,r.jsxs)(n.td,{children:["Loads the model. Checkout the ",(0,r.jsx)(n.a,{href:"#loading-the-model",children:"loading the model"})," section for details."]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"onDownloadProgress"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"(callback: (downloadProgress: number) => void): any"})}),(0,r.jsx)(n.td,{children:"Subscribe to the download progress event."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"generate"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"(input: string): Promise<void>"})}),(0,r.jsx)(n.td,{children:"Method to start generating a response with the given input string."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"onToken"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)("code",{children:"(callback: (data: string | undefined) => void): any"})}),(0,r.jsx)(n.td,{children:"Subscribe to the token generation event."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"interrupt"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"(): void"})}),(0,r.jsx)(n.td,{children:"Method to interrupt the current inference"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"delete"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"(): void"})}),(0,r.jsx)(n.td,{children:"Method to delete the model from memory."})]})]})]}),"\n",(0,r.jsxs)(o,{children:[(0,r.jsx)("summary",{children:"Type definitions"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"type ResourceSource = string | number;\n\ninterface MessageType {\n  role: 'user' | 'assistant';\n  content: string;\n}\n"})})]}),"\n",(0,r.jsx)(n.h2,{id:"loading-the-model",children:"Loading the model"}),"\n",(0,r.jsxs)(n.p,{children:["To load the model, use the ",(0,r.jsx)(n.code,{children:"load"})," method. It accepts:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"modelSource"})," - A string that specifies the location of the model binary. For more information, take a look at ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/0.3.x/fundamentals/loading-models",children:"loading models"})," page."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"tokenizerSource"})," - URL to the binary file which contains the tokenizer"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"systemPrompt"}),' - Often used to tell the model what is its purpose, for example - "Be a helpful translator"']}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"messageHistory"})," - An array of ",(0,r.jsx)(n.code,{children:"MessageType"})," objects that represent the conversation history. This can be used to provide context to the model."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"contextWindowLength"})," - The number of messages from the current conversation that the model will use to generate a response. The higher the number, the more context the model will have. Keep in mind that using larger context windows will result in longer inference time and higher memory usage."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"This method returns a promise, which can resolve to an error or void."}),"\n",(0,r.jsx)(n.h2,{id:"listening-for-download-progress",children:"Listening for download progress"}),"\n",(0,r.jsxs)(n.p,{children:["To subscribe to the download progress event, you can use the ",(0,r.jsx)(n.code,{children:"onDownloadProgress"})," method. It accepts a callback function that will be called whenever the download progress changes."]}),"\n",(0,r.jsx)(n.h2,{id:"running-the-model",children:"Running the model"}),"\n",(0,r.jsxs)(n.p,{children:["To run the model, you can use the ",(0,r.jsx)(n.code,{children:"generate"})," method. It accepts one argument, which is the input string. The method returns a promise, which can resolve to an error or void."]}),"\n",(0,r.jsx)(n.h2,{id:"listening-for-token",children:"Listening for token"}),"\n",(0,r.jsxs)(n.p,{children:["To subscribe to the token event, you can use the ",(0,r.jsx)(n.code,{children:"onToken"})," method. It accepts a callback function that will be called whenever a token is generated."]}),"\n",(0,r.jsx)(n.h2,{id:"interrupting-the-model",children:"Interrupting the model"}),"\n",(0,r.jsxs)(n.p,{children:["In order to interrupt the model, you can use the ",(0,r.jsx)(n.code,{children:"interrupt"})," method."]}),"\n",(0,r.jsx)(n.h2,{id:"deleting-the-model-from-memory",children:"Deleting the model from memory"}),"\n",(0,r.jsxs)(n.p,{children:["To delete the model from memory, you can use the ",(0,r.jsx)(n.code,{children:"delete"})," method."]})]})}function a(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}},8453:(e,n,o)=>{o.d(n,{R:()=>d,x:()=>i});var t=o(6540);const r={},s=t.createContext(r);function d(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:d(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);