"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[62051],{28453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>s});var r=t(96540);const c={},i=r.createContext(c);function o(e){const n=r.useContext(i);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(c):e.components||c:o(e.components),r.createElement(i.Provider,{value:n},e.children)}},34306:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>s,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"hooks/computer-vision/useVerticalOCR","title":"useVerticalOCR","description":"The useVerticalOCR hook is currently in an experimental phase. We appreciate feedback from users as we continue to refine and enhance its functionality.","source":"@site/docs/03-hooks/02-computer-vision/useVerticalOCR.md","sourceDirName":"03-hooks/02-computer-vision","slug":"/hooks/computer-vision/useVerticalOCR","permalink":"/react-native-executorch/docs/next/hooks/computer-vision/useVerticalOCR","draft":false,"unlisted":false,"editUrl":"https://github.com/software-mansion/react-native-executorch/edit/main/docs/docs/03-hooks/02-computer-vision/useVerticalOCR.md","tags":[],"version":"current","frontMatter":{"title":"useVerticalOCR"},"sidebar":"tutorialSidebar","previous":{"title":"useTextToImage","permalink":"/react-native-executorch/docs/next/hooks/computer-vision/useTextToImage"},"next":{"title":"ExecuTorch Bindings","permalink":"/react-native-executorch/docs/next/category/executorch-bindings"}}');var c=t(74848),i=t(28453);const o={title:"useVerticalOCR"},s=void 0,a={},l=[{value:"API Reference",id:"api-reference",level:2},{value:"High Level Overview",id:"high-level-overview",level:2},{value:"Arguments",id:"arguments",level:3},{value:"Returns",id:"returns",level:3},{value:"Running the model",id:"running-the-model",level:2},{value:"Detection object",id:"detection-object",level:2},{value:"Example",id:"example",level:2},{value:"Alphabet-Specific Recognizers",id:"alphabet-specific-recognizers",level:2},{value:"Supported languages",id:"supported-languages",level:2},{value:"Supported models",id:"supported-models",level:2}];function d(e){const n={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,c.jsxs)(c.Fragment,{children:[(0,c.jsx)(n.admonition,{title:"Experimental",type:"danger",children:(0,c.jsxs)(n.p,{children:["The ",(0,c.jsx)(n.code,{children:"useVerticalOCR"})," hook is currently in an experimental phase. We appreciate feedback from users as we continue to refine and enhance its functionality."]})}),"\n",(0,c.jsxs)(n.p,{children:["Optical Character Recognition (OCR) is a computer vision technique used to detect and recognize text within images. It is commonly utilized to convert a variety of documents, such as scanned paper documents, PDF files, or images captured by a digital camera, into editable and searchable data. Traditionally, OCR technology has been optimized for recognizing horizontal text, and integrating support for vertical text recognition often requires significant additional effort from developers. To simplify this, we introduce ",(0,c.jsx)(n.code,{children:"useVerticalOCR"}),", a tool designed to abstract the complexities of vertical text OCR, enabling seamless integration into your applications."]}),"\n",(0,c.jsx)(n.admonition,{type:"warning",children:(0,c.jsxs)(n.p,{children:["It is recommended to use models provided by us, which are available at our ",(0,c.jsx)(n.a,{href:"https://huggingface.co/collections/software-mansion/ocr-68d0eb320ae6d20b5f901ea9",children:"Hugging Face repository"}),". You can also use ",(0,c.jsx)(n.a,{href:"https://github.com/software-mansion/react-native-executorch/blob/main/packages/react-native-executorch/src/constants/modelUrls.ts",children:"constants"})," shipped with our library."]})}),"\n",(0,c.jsx)(n.h2,{id:"api-reference",children:"API Reference"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:["For detailed API Reference for ",(0,c.jsx)(n.code,{children:"useVerticalOCR"})," see: ",(0,c.jsxs)(n.a,{href:"/react-native-executorch/docs/next/api-reference/functions/useVerticalOCR",children:[(0,c.jsx)(n.code,{children:"useVerticalOCR"})," API Reference"]}),"."]}),"\n",(0,c.jsxs)(n.li,{children:["For all alphabets available in ocr out-of-the-box in React Native ExecuTorch see: ",(0,c.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/#ocr-supported-alphabets",children:"OCR Supported Alphabets"}),"."]}),"\n"]}),"\n",(0,c.jsx)(n.h2,{id:"high-level-overview",children:"High Level Overview"}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-tsx",children:"import { useVerticalOCR, OCR_ENGLISH } from 'react-native-executorch';\n\nfunction App() {\n  const model = useVerticalOCR({\n    model: OCR_ENGLISH,\n    independentCharacters: true,\n  });\n\n  // ...\n  for (const ocrDetection of await model.forward('https://url-to-image.jpg')) {\n    console.log('Bounding box: ', ocrDetection.bbox);\n    console.log('Bounding label: ', ocrDetection.text);\n    console.log('Bounding score: ', ocrDetection.score);\n  }\n  // ...\n}\n"})}),"\n",(0,c.jsx)(n.h3,{id:"arguments",children:"Arguments"}),"\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.code,{children:"useVerticalOCR"})," takes ",(0,c.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/VerticalOCRProps",children:(0,c.jsx)(n.code,{children:"VerticalOCRProps"})})," that consists of:"]}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"model"})," containing ",(0,c.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/VerticalOCRProps#detectorsource",children:(0,c.jsx)(n.code,{children:"detectorSource"})}),", ",(0,c.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/VerticalOCRProps#recognizersource",children:(0,c.jsx)(n.code,{children:"recognizerSource"})}),", and ",(0,c.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/VerticalOCRProps#language",children:(0,c.jsx)(n.code,{children:"language"})}),"."]}),"\n",(0,c.jsxs)(n.li,{children:["An optional flag ",(0,c.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/VerticalOCRProps#preventload",children:(0,c.jsx)(n.code,{children:"preventLoad"})})," which prevents auto-loading of the model."]}),"\n",(0,c.jsxs)(n.li,{children:["An optional flag ",(0,c.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/VerticalOCRProps#independentcharacters",children:(0,c.jsx)(n.code,{children:"independentCharacters"})})," indicating either to treat characters as independent or words."]}),"\n"]}),"\n",(0,c.jsx)(n.p,{children:"You need more details? Check the following resources:"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:["For detailed information about ",(0,c.jsx)(n.code,{children:"useVerticalOCR"})," arguments check this section: ",(0,c.jsxs)(n.a,{href:"/react-native-executorch/docs/next/api-reference/functions/useVerticalOCR#parameters",children:[(0,c.jsx)(n.code,{children:"useVerticalOCR"})," arguments"]}),"."]}),"\n",(0,c.jsxs)(n.li,{children:["For all alphabets available in ocr out-of-the-box in React Native ExecuTorch see: ",(0,c.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/#ocr-supported-alphabets",children:"OCR Supported Alphabets"}),"."]}),"\n",(0,c.jsxs)(n.li,{children:["For more information on loading resources, take a look at ",(0,c.jsx)(n.a,{href:"/react-native-executorch/docs/next/fundamentals/loading-models",children:"loading models"})," page."]}),"\n"]}),"\n",(0,c.jsx)(n.h3,{id:"returns",children:"Returns"}),"\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.code,{children:"useVerticalOCR"})," returns an object called ",(0,c.jsx)(n.code,{children:"OCRType"})," containing bunch of functions to interact with Vertical OCR models. To get more details please read: ",(0,c.jsxs)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/OCRType",children:[(0,c.jsx)(n.code,{children:"OCRType"})," API Reference"]}),"."]}),"\n",(0,c.jsx)(n.h2,{id:"running-the-model",children:"Running the model"}),"\n",(0,c.jsxs)(n.p,{children:["To run the model, you can use the ",(0,c.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/OCRType#forward",children:(0,c.jsx)(n.code,{children:"forward"})})," method. It accepts one argument, which is the image. The image can be a remote URL, a local file URI, or a base64-encoded image. The function returns an array of ",(0,c.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/OCRDetection",children:(0,c.jsx)(n.code,{children:"OCRDetection"})})," objects. Each object contains coordinates of the bounding box, the text recognized within the box, and the confidence score. For more information, please refer to the reference or type definitions."]}),"\n",(0,c.jsx)(n.h2,{id:"detection-object",children:"Detection object"}),"\n",(0,c.jsx)(n.p,{children:"The detection object is specified as follows:"}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-typescript",children:"interface Point {\n  x: number;\n  y: number;\n}\n\ninterface OCRDetection {\n  bbox: Point[];\n  text: string;\n  score: number;\n}\n"})}),"\n",(0,c.jsxs)(n.p,{children:["The ",(0,c.jsx)(n.code,{children:"bbox"})," property contains information about the bounding box of detected text regions. It is represented as four points, which are corners of detected bounding box.\nThe ",(0,c.jsx)(n.code,{children:"text"})," property contains the text recognized within detected text region. The ",(0,c.jsx)(n.code,{children:"score"})," represents the confidence score of the recognized text."]}),"\n",(0,c.jsx)(n.h2,{id:"example",children:"Example"}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-tsx",children:"import { useVerticalOCR, OCR_ENGLISH } from 'react-native-executorch';\n\nfunction App() {\n  const model = useVerticalOCR({\n    model: OCR_ENGLISH,\n    independentCharacters: true,\n  });\n\n  const runModel = async () => {\n    const ocrDetections = await model.forward('https://url-to-image.jpg');\n\n    for (const ocrDetection of ocrDetections) {\n      console.log('Bounding box: ', ocrDetection.bbox);\n      console.log('Bounding text: ', ocrDetection.text);\n      console.log('Bounding score: ', ocrDetection.score);\n    }\n  };\n}\n"})}),"\n",(0,c.jsx)(n.h2,{id:"alphabet-specific-recognizers",children:"Alphabet-Specific Recognizers"}),"\n",(0,c.jsxs)(n.p,{children:["Each supported alphabet requires its own recognizer model. The built-in constants, such as ",(0,c.jsx)(n.code,{children:"RECOGNIZER_LATIN_CRNN"})," or ",(0,c.jsx)(n.code,{children:"RECOGNIZER_CYRILLIC_CRNN"}),", point to specific models trained for a particular alphabet."]}),"\n",(0,c.jsxs)(n.blockquote,{children:["\n",(0,c.jsx)(n.p,{children:"For example:"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:["To recognize text in languages using the ",(0,c.jsx)(n.strong,{children:"Latin"})," alphabet (like Polish, or German), use:","\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsx)(n.li,{children:(0,c.jsx)(n.code,{children:"RECOGNIZER_LATIN_CRNN"})}),"\n"]}),"\n"]}),"\n",(0,c.jsxs)(n.li,{children:["To recognize text in languages using the ",(0,c.jsx)(n.strong,{children:"Cyrillic"})," alphabet (like Russian or Ukrainian), use:","\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsx)(n.li,{children:(0,c.jsx)(n.code,{children:"RECOGNIZER_CYRILLIC_CRNN"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,c.jsxs)(n.p,{children:["You need to make sure the recognizer model you pass in ",(0,c.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/VerticalOCRProps#recognizersource",children:(0,c.jsx)(n.code,{children:"recognizerSource"})})," matches the alphabet of the ",(0,c.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/interfaces/VerticalOCRProps#language",children:(0,c.jsx)(n.code,{children:"language"})})," you specify."]}),"\n",(0,c.jsx)(n.h2,{id:"supported-languages",children:"Supported languages"}),"\n",(0,c.jsxs)(n.p,{children:["For all alphabets available in ocr out-of-the-box in React Native ExecuTorch see: ",(0,c.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/#ocr-supported-alphabets",children:"OCR Supported Alphabets"}),"."]}),"\n",(0,c.jsx)(n.h2,{id:"supported-models",children:"Supported models"}),"\n",(0,c.jsxs)(n.table,{children:[(0,c.jsx)(n.thead,{children:(0,c.jsxs)(n.tr,{children:[(0,c.jsx)(n.th,{children:"Model"}),(0,c.jsx)(n.th,{style:{textAlign:"center"},children:"Type"})]})}),(0,c.jsxs)(n.tbody,{children:[(0,c.jsxs)(n.tr,{children:[(0,c.jsx)(n.td,{children:(0,c.jsx)(n.a,{href:"https://github.com/clovaai/CRAFT-pytorch",children:"CRAFT"})}),(0,c.jsx)(n.td,{style:{textAlign:"center"},children:"Detector"})]}),(0,c.jsxs)(n.tr,{children:[(0,c.jsx)(n.td,{children:(0,c.jsx)(n.a,{href:"https://www.jaided.ai/easyocr/modelhub/",children:"CRNN"})}),(0,c.jsx)(n.td,{style:{textAlign:"center"},children:"Recognizer"})]})]})]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,c.jsx)(n,{...e,children:(0,c.jsx)(d,{...e})}):d(e)}}}]);