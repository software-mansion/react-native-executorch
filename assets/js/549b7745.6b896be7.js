"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[71302],{27936:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>a,contentTitle:()=>i,default:()=>h,frontMatter:()=>s,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"typescript-api/computer-vision/TextToImageModule","title":"TextToImageModule","description":"TypeScript API implementation of the useTextToImage hook.","source":"@site/docs/04-typescript-api/02-computer-vision/TextToImageModule.md","sourceDirName":"04-typescript-api/02-computer-vision","slug":"/typescript-api/computer-vision/TextToImageModule","permalink":"/react-native-executorch/docs/next/typescript-api/computer-vision/TextToImageModule","draft":false,"unlisted":false,"editUrl":"https://github.com/software-mansion/react-native-executorch/edit/main/docs/docs/04-typescript-api/02-computer-vision/TextToImageModule.md","tags":[],"version":"current","frontMatter":{"title":"TextToImageModule"},"sidebar":"tutorialSidebar","previous":{"title":"StyleTransferModule","permalink":"/react-native-executorch/docs/next/typescript-api/computer-vision/StyleTransferModule"},"next":{"title":"VerticalOCRModule","permalink":"/react-native-executorch/docs/next/typescript-api/computer-vision/VerticalOCRModule"}}');var r=o(74848),c=o(28453);const s={title:"TextToImageModule"},i=void 0,a={},l=[{value:"API Reference",id:"api-reference",level:2},{value:"High Level Overview",id:"high-level-overview",level:2},{value:"Methods",id:"methods",level:3},{value:"Loading the model",id:"loading-the-model",level:2},{value:"Running the model",id:"running-the-model",level:2},{value:"Listening for inference steps",id:"listening-for-inference-steps",level:2},{value:"Deleting the model from memory",id:"deleting-the-model-from-memory",level:2}];function d(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,c.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(n.p,{children:["TypeScript API implementation of the ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/hooks/computer-vision/useTextToImage",children:"useTextToImage"})," hook."]}),"\n",(0,r.jsx)(n.h2,{id:"api-reference",children:"API Reference"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["For detailed API Reference for ",(0,r.jsx)(n.code,{children:"TextToImageModule"})," see: ",(0,r.jsxs)(n.a,{href:"/react-native-executorch/docs/next/api-reference/classes/TextToImageModule",children:[(0,r.jsx)(n.code,{children:"TextToImageModule"})," API Reference"]}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["For all text to image models available out-of-the-box in React Native ExecuTorch see: ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/#models---image-generation",children:"Text to Image Models"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"high-level-overview",children:"High Level Overview"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"import {\n  TextToImageModule,\n  BK_SDM_TINY_VPRED_256,\n} from 'react-native-executorch';\n\nconst input = 'a castle';\n\n// Creating an instance\nconst textToImageModule = new TextToImageModule();\n\n// Loading the model\nawait textToImageModule.load(BK_SDM_TINY_VPRED_256);\n\n// Running the model\nconst image = await textToImageModule.forward(input);\n"})}),"\n",(0,r.jsx)(n.h3,{id:"methods",children:"Methods"}),"\n",(0,r.jsxs)(n.p,{children:["All methods of ",(0,r.jsx)(n.code,{children:"TextToImageModule"})," are explained in details here: ",(0,r.jsxs)(n.a,{href:"/react-native-executorch/docs/next/api-reference/classes/TextToImageModule",children:[(0,r.jsx)(n.code,{children:"TextToImageModule"})," API Reference"]})]}),"\n",(0,r.jsx)(n.h2,{id:"loading-the-model",children:"Loading the model"}),"\n",(0,r.jsxs)(n.p,{children:["To load the model, use the ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/classes/TextToImageModule#load",children:(0,r.jsx)(n.code,{children:"load"})})," method. It accepts an object:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/classes/TextToImageModule#model",children:(0,r.jsx)(n.code,{children:"model"})})," - Object containing:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/classes/TextToImageModule#schedulersource",children:(0,r.jsx)(n.code,{children:"schedulerSource"})})," - Location of the used scheduler."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/classes/TextToImageModule#tokenizersource",children:(0,r.jsx)(n.code,{children:"tokenizerSource"})})," - Location of the used tokenizer."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/classes/TextToImageModule#encodersource",children:(0,r.jsx)(n.code,{children:"encoderSource"})})," - Location of the used encoder."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/classes/TextToImageModule#unetsource",children:(0,r.jsx)(n.code,{children:"unetSource"})})," - Location of the used unet."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/classes/TextToImageModule#decodersource",children:(0,r.jsx)(n.code,{children:"decoderSource"})})," - Location of the used decoder."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/classes/TextToImageModule#ondownloadprogresscallback",children:(0,r.jsx)(n.code,{children:"onDownloadProgressCallback"})})," - Callback to track download progress."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"This method returns a promise, which can resolve to an error or void."}),"\n",(0,r.jsxs)(n.p,{children:["For more information on loading resources, take a look at ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/fundamentals/loading-models",children:"loading models"})," page."]}),"\n",(0,r.jsx)(n.h2,{id:"running-the-model",children:"Running the model"}),"\n",(0,r.jsxs)(n.p,{children:["To run the model, you can use the ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/classes/TextToImageModule#forward",children:(0,r.jsx)(n.code,{children:"forward"})})," method. It accepts four arguments: a text prompt describing the requested image, a size of the image in pixels, a number of denoising steps, and an optional seed value, which enables reproducibility of the results."]}),"\n",(0,r.jsx)(n.p,{children:"The image size must fall within the range from 128 to 512 unless specified differently, and be a multiple of 32 due to the architecture of the U-Net and VAE models."}),"\n",(0,r.jsx)(n.p,{children:"The seed value should be a positive integer."}),"\n",(0,r.jsx)(n.h2,{id:"listening-for-inference-steps",children:"Listening for inference steps"}),"\n",(0,r.jsxs)(n.p,{children:["To monitor the progress of image generation, you can pass an ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/classes/TextToImageModule#inferencecallback",children:(0,r.jsx)(n.code,{children:"inferenceCallback"})})," function to the ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/classes/TextToImageModule#constructor",children:"constructor"}),". The callback is invoked at each denoising step (for a total of ",(0,r.jsx)(n.code,{children:"numSteps + 1"})," times), yielding the current step index that can be used, for example, to display a progress bar."]}),"\n",(0,r.jsx)(n.h2,{id:"deleting-the-model-from-memory",children:"Deleting the model from memory"}),"\n",(0,r.jsxs)(n.p,{children:["To delete the model from memory, you can use the ",(0,r.jsx)(n.a,{href:"/react-native-executorch/docs/next/api-reference/classes/TextToImageModule#delete",children:(0,r.jsx)(n.code,{children:"delete"})})," method."]})]})}function h(e={}){const{wrapper:n}={...(0,c.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},28453:(e,n,o)=>{o.d(n,{R:()=>s,x:()=>i});var t=o(96540);const r={},c=t.createContext(r);function s(e){const n=t.useContext(c);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),t.createElement(c.Provider,{value:n},e.children)}}}]);