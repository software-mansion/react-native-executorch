"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[242],{3262:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>h,frontMatter:()=>s,metadata:()=>o,toc:()=>a});const o=JSON.parse('{"id":"natural-language-processing/useTokenizer","title":"useTokenizer","description":"Learn how to tokenize your text in your React Native applications using React Native ExecuTorch\'s useTokenizer hook.","source":"@site/versioned_docs/version-0.4.x/natural-language-processing/useTokenizer.md","sourceDirName":"natural-language-processing","slug":"/natural-language-processing/useTokenizer","permalink":"/react-native-executorch/docs/natural-language-processing/useTokenizer","draft":false,"unlisted":false,"editUrl":"https://github.com/software-mansion/react-native-executorch/edit/main/docs/versioned_docs/version-0.4.x/natural-language-processing/useTokenizer.md","tags":[],"version":"0.4.x","frontMatter":{"title":"useTokenizer","keywords":["tokenizer","text tokenizer","tokenization","react native","executorch","ai","machine learning","on-device","mobile ai"],"description":"Learn how to tokenize your text in your React Native applications using React Native ExecuTorch\'s useTokenizer hook."},"sidebar":"tutorialSidebar","previous":{"title":"useTextEmbeddings","permalink":"/react-native-executorch/docs/natural-language-processing/useTextEmbeddings"},"next":{"title":"Computer Vision","permalink":"/react-native-executorch/docs/category/computer-vision"}}');var r=t(4848),i=t(8453);const s={title:"useTokenizer",keywords:["tokenizer","text tokenizer","tokenization","react native","executorch","ai","machine learning","on-device","mobile ai"],description:"Learn how to tokenize your text in your React Native applications using React Native ExecuTorch's useTokenizer hook."},c=void 0,d={},a=[{value:"Reference",id:"reference",level:2},{value:"Arguments",id:"arguments",level:2},{value:"Returns",id:"returns",level:3},{value:"Example",id:"example",level:2}];function l(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.p,{children:"Tokenization is the process of breaking down text into smaller units called tokens. It\u2019s a crucial step in natural language processing that\nconverts text into a format that machine learning models can understand."}),"\n",(0,r.jsx)(n.admonition,{type:"info",children:(0,r.jsxs)(n.p,{children:["We are using ",(0,r.jsx)(n.a,{href:"https://huggingface.co/docs/tokenizers/index",children:"Hugging Face Tokenizers"})," under the hood, ensuring compatibility with the Hugging Face ecosystem."]})}),"\n",(0,r.jsx)(n.h2,{id:"reference",children:"Reference"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"import {\n  useTokenizer,\n  ALL_MINILM_L6_V2_TOKENIZER,\n} from 'react-native-executorch';\n\nconst tokenizer = useTokenizer({\n  tokenizerSource: ALL_MINILM_L6_V2_TOKENIZER,\n});\n\nconst text = 'Hello, world!';\n\ntry {\n  // Tokenize the text\n  const tokens = await tokenizer.encode(text);\n  console.log('Tokens:', tokens);\n\n  // Decode the tokens back to text\n  const decodedText = await tokenizer.decode(tokens);\n  console.log('Decoded text:', decodedText);\n} catch (error) {\n  console.error('Error tokenizing text:', error);\n}\n"})}),"\n",(0,r.jsx)(n.h2,{id:"arguments",children:"Arguments"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"tokenizerSource"})})," - A string that specifies the path or URI of the tokenizer JSON file."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"preventLoad?"})})," - Boolean that can prevent automatic model loading (and downloading the data if you load it for the first time) after running the hook."]}),"\n",(0,r.jsx)(n.h3,{id:"returns",children:"Returns"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Field"}),(0,r.jsx)(n.th,{children:"Type"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"encode"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"(text: string) => Promise<number[]>"})}),(0,r.jsx)(n.td,{children:"Converts a string into an array of token IDs."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"decode"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"(ids: number[]) => Promise<string>"})}),(0,r.jsx)(n.td,{children:"Converts an array of token IDs into a string."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"getVocabSize"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"() => Promise<number>"})}),(0,r.jsx)(n.td,{children:"Returns the size of the tokenizer's vocabulary."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"idToToken"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"(id: number) => Promise<string>"})}),(0,r.jsx)(n.td,{children:"Returns the token associated to the ID."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"tokenToId"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"(token: string) => Promise<number>"})}),(0,r.jsx)(n.td,{children:"Returns the ID associated to the token."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"error"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)("code",{children:"string | null"})}),(0,r.jsx)(n.td,{children:"Contains the error message if the tokenizer failed to load."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"isGenerating"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"boolean"})}),(0,r.jsx)(n.td,{children:"Indicates whether the tokenizer is currently running."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"isReady"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"boolean"})}),(0,r.jsx)(n.td,{children:"Indicates whether the tokenizer has successfully loaded and is ready."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"downloadProgress"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"number"})}),(0,r.jsx)(n.td,{children:"Represents the download progress as a value between 0 and 1."})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"example",children:"Example"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"import {\n  useTokenizer,\n  ALL_MINILM_L6_V2_TOKENIZER,\n} from 'react-native-executorch';\n\nfunction App() {\n  const tokenizer = useTokenizer({\n    tokenizerSource: ALL_MINILM_L6_V2_TOKENIZER,\n  });\n\n  ...\n\n  try {\n    const text = 'Hello, world!';\n\n    const vocabSize = await tokenizer.getVocabSize();\n    console.log('Vocabulary size:', vocabSize);\n\n    const tokens = await tokenizer.encode(text);\n    console.log('Token IDs:', tokens);\n\n    const decoded = await tokenizer.decode(tokens);\n    console.log('Decoded text:', decoded);\n\n    const tokenId = await tokenizer.tokenToId('hello');\n    console.log('Token ID for \"Hello\":', tokenId);\n\n    const token = await tokenizer.idToToken(tokenId);\n    console.log('Token for ID:', token);\n  } catch (error) {\n    console.error(error);\n  }\n\n  ...\n}\n"})})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>c});var o=t(6540);const r={},i=o.createContext(r);function s(e){const n=o.useContext(i);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),o.createElement(i.Provider,{value:n},e.children)}}}]);