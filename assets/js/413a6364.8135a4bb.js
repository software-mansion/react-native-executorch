"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[2437],{1090:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>i,contentTitle:()=>l,default:()=>u,frontMatter:()=>a,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"fundamentals/loading-models","title":"Loading Models","description":"There are three different methods available for loading model files, depending on their size and location.","source":"@site/docs/01-fundamentals/02-loading-models.md","sourceDirName":"01-fundamentals","slug":"/fundamentals/loading-models","permalink":"/react-native-executorch/docs/next/fundamentals/loading-models","draft":false,"unlisted":false,"editUrl":"https://github.com/software-mansion/react-native-executorch/edit/main/docs/docs/01-fundamentals/02-loading-models.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Loading Models"},"sidebar":"tutorialSidebar","previous":{"title":"Getting Started","permalink":"/react-native-executorch/docs/next/"},"next":{"title":"Frequently Asked Questions","permalink":"/react-native-executorch/docs/next/fundamentals/frequently-asked-questions"}}');var s=t(4848),r=t(8453);const a={title:"Loading Models"},l=void 0,i={},d=[{value:"Example",id:"example",level:2}];function c(e){const n={admonition:"admonition",code:"code",h2:"h2",p:"p",pre:"pre",strong:"strong",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:"There are three different methods available for loading model files, depending on their size and location."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"1. Load from React Native assets folder (For Files < 512MB)"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"useExecutorchModule({\n  modelSource: require('../assets/llama3_2.pte'),\n});\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"2. Load from remote URL:"})}),"\n",(0,s.jsx)(n.p,{children:"For files larger than 512MB or when you want to keep size of the app smaller, you can load the model from a remote URL (e.g. HuggingFace)."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"useExecutorchModule({\n  modelSource: 'https://.../llama3_2.pte',\n});\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"3. Load from local file system:"})}),"\n",(0,s.jsx)(n.p,{children:"If you prefer to delegate the process of obtaining and loading model and tokenizer files to the user, you can use the following method:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"useExecutorchModule({\n  modelSource: 'file:///var/mobile/.../llama3_2.pte',\n});\n"})}),"\n",(0,s.jsx)(n.admonition,{type:"info",children:(0,s.jsx)(n.p,{children:"The downloaded files are stored in documents directory of your application."})}),"\n",(0,s.jsx)(n.h2,{id:"example",children:"Example"}),"\n",(0,s.jsxs)(n.p,{children:["The following code snippet demonstrates how to load model and tokenizer files using ",(0,s.jsx)(n.code,{children:"useLLM"})," hook:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"import { useLLM } from 'react-native-executorch';\n\nconst llama = useLLM({\n  modelSource: 'https://.../llama3_2.pte',\n  tokenizerSource: require('../assets/tokenizer.bin'),\n});\n"})})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>l});var o=t(6540);const s={},r=o.createContext(s);function a(e){const n=o.useContext(r);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),o.createElement(r.Provider,{value:n},e.children)}}}]);