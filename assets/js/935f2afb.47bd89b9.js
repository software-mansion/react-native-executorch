"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[581],{5610:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Fundamentals","collapsible":false,"collapsed":false,"items":[{"type":"link","label":"Getting Started","href":"/react-native-executorch/docs/fundamentals/getting-started","docId":"fundamentals/getting-started"}],"href":"/react-native-executorch/docs/category/fundamentals"},{"type":"category","label":"Guides","collapsible":false,"collapsed":false,"items":[{"type":"link","label":"Running LLMs","href":"/react-native-executorch/docs/guides/running-llms","docId":"guides/running-llms"},{"type":"link","label":"Exporting Llama","href":"/react-native-executorch/docs/guides/exporting-llama","docId":"guides/exporting-llama"}],"href":"/react-native-executorch/docs/category/guides"},{"type":"category","label":"Computer Vision","collapsible":false,"collapsed":false,"items":[{"type":"link","label":"useObjectDetection","href":"/react-native-executorch/docs/computer_vision/useObjectDetection","docId":"computer_vision/useObjectDetection"}],"href":"/react-native-executorch/docs/category/computer-vision"}]},"docs":{"computer_vision/useObjectDetection":{"id":"computer_vision/useObjectDetection","title":"useObjectDetection","description":"Object detection is a computer vision technique that identifies and locates objects within images or video. It\u2019s commonly used in applications like image recognition, video surveillance or autonomous driving.","sidebar":"tutorialSidebar"},"fundamentals/getting-started":{"id":"fundamentals/getting-started","title":"Getting Started","description":"What is ExecuTorch?","sidebar":"tutorialSidebar"},"guides/exporting-llama":{"id":"guides/exporting-llama","title":"Exporting Llama","description":"In order to make the process of export as simple as possible for you, we created a script that runs a Docker container and exports the model.","sidebar":"tutorialSidebar"},"guides/running-llms":{"id":"guides/running-llms","title":"Running LLMs","description":"React Native ExecuTorch supports Llama 3.2 models, including quantized versions. Before getting started, you\u2019ll need to obtain the .pte binary\u2014a serialized model\u2014and the tokenizer. There are various ways to accomplish this:","sidebar":"tutorialSidebar"}}}')}}]);