"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[87624],{11729:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>d,default:()=>h,frontMatter:()=>s,metadata:()=>r,toc:()=>a});const r=JSON.parse('{"id":"executorch-bindings/useExecutorchModule","title":"useExecutorchModule","description":"ExecuTorch bindings provide streamlined interface to access the Module API directly from Javascript.","source":"@site/versioned_docs/version-0.4.x/executorch-bindings/useExecutorchModule.md","sourceDirName":"executorch-bindings","slug":"/executorch-bindings/useExecutorchModule","permalink":"/react-native-executorch/docs/0.4.x/executorch-bindings/useExecutorchModule","draft":false,"unlisted":false,"editUrl":"https://github.com/software-mansion/react-native-executorch/edit/main/docs/versioned_docs/version-0.4.x/executorch-bindings/useExecutorchModule.md","tags":[],"version":"0.4.x","frontMatter":{"title":"useExecutorchModule"},"sidebar":"tutorialSidebar","previous":{"title":"ExecuTorch bindings","permalink":"/react-native-executorch/docs/0.4.x/category/executorch-bindings"},"next":{"title":"Natural Language Processing","permalink":"/react-native-executorch/docs/0.4.x/category/natural-language-processing-1"}}');var i=t(74848),o=t(28453);const s={title:"useExecutorchModule"},d=void 0,c={},a=[{value:"Initializing ExecuTorch Module",id:"initializing-executorch-module",level:2},{value:"Arguments",id:"arguments",level:3},{value:"Returns",id:"returns",level:3},{value:"ETInput",id:"etinput",level:2},{value:"Errors",id:"errors",level:2},{value:"Performing inference",id:"performing-inference",level:2},{value:"End to end example",id:"end-to-end-example",level:2},{value:"Importing the Module and loading the model",id:"importing-the-module-and-loading-the-model",level:3},{value:"Setting up input parameters",id:"setting-up-input-parameters",level:3},{value:"Performing inference",id:"performing-inference-1",level:3}];function l(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(n.p,{children:["ExecuTorch bindings provide streamlined interface to access the ",(0,i.jsx)(n.a,{href:"https://pytorch.org/executorch/stable/extension-module.html",children:"Module API"})," directly from Javascript."]}),"\n",(0,i.jsx)(n.admonition,{type:"caution",children:(0,i.jsx)(n.p,{children:"These bindings are primarily intended for custom model integration where no dedicated hook exists. If you are considering using a provided model, first verify whether a dedicated hook is available. Dedicated hooks simplify the implementation process by managing necessary pre and post-processing automatically. Utilizing these can save you effort and reduce complexity, ensuring you do not implement additional handling that is already covered."})}),"\n",(0,i.jsx)(n.h2,{id:"initializing-executorch-module",children:"Initializing ExecuTorch Module"}),"\n",(0,i.jsxs)(n.p,{children:["You can initialize the ExecuTorch module in your JavaScript application using the ",(0,i.jsx)(n.code,{children:"useExecutorchModule"})," hook. This hook facilitates the loading of models from the specified source and prepares them for use."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"import { useExecutorchModule } from 'react-native-executorch';\n\nconst executorchModule = useExecutorchModule({\n  modelSource: require('../assets/models/model.pte'),\n});\n"})}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"modelSource"})," parameter expects a location string pointing to the model binary. For more details on how to specify model sources, refer to the ",(0,i.jsx)(n.a,{href:"/react-native-executorch/docs/0.4.x/fundamentals/loading-models",children:"loading models"})," documentation."]}),"\n",(0,i.jsx)(n.h3,{id:"arguments",children:"Arguments"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.code,{children:"modelSource"})})," - A string that specifies the location of the model binary."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.code,{children:"preventLoad?"})})," - Boolean that can prevent automatic model loading (and downloading the data if you load it for the first time) after running the hook."]}),"\n",(0,i.jsx)(n.h3,{id:"returns",children:"Returns"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{style:{textAlign:"center"},children:"Field"}),(0,i.jsx)(n.th,{style:{textAlign:"center"},children:"Type"}),(0,i.jsx)(n.th,{style:{textAlign:"center"},children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"center"},children:(0,i.jsx)(n.code,{children:"error"})}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:(0,i.jsx)("code",{children:"string | null"})}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"Contains the error message if the model failed to load."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"center"},children:(0,i.jsx)(n.code,{children:"isGenerating"})}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:(0,i.jsx)(n.code,{children:"boolean"})}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"Indicates whether the model is currently processing an inference."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"center"},children:(0,i.jsx)(n.code,{children:"isReady"})}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:(0,i.jsx)(n.code,{children:"boolean"})}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"Indicates whether the model has successfully loaded and is ready for inference."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"center"},children:(0,i.jsx)(n.code,{children:"forward"})}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:(0,i.jsx)(n.code,{children:"(input: ETInput[] | ETInput, shape: number[][]): Promise<unknown>"})}),(0,i.jsxs)(n.td,{style:{textAlign:"center"},children:["Executes the model's forward pass, where ",(0,i.jsx)(n.code,{children:"input"})," is a Javascript typed array or an array of them, and ",(0,i.jsx)(n.code,{children:"shape"})," is an array of arrays of integers representing input Tensors' shapes. The output is a Tensor - raw result of inference."]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"center"},children:(0,i.jsx)(n.code,{children:"downloadProgress"})}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:(0,i.jsx)(n.code,{children:"number"})}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"Represents the download progress as a value between 0 and 1."})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"etinput",children:"ETInput"}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"ETInput"})," type defines the typed arrays that can be used as inputs in the ",(0,i.jsx)(n.code,{children:"forward"})," method:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Int8Array"}),"\n",(0,i.jsx)(n.li,{children:"Int32Array"}),"\n",(0,i.jsx)(n.li,{children:"BigInt64Array"}),"\n",(0,i.jsx)(n.li,{children:"Float32Array"}),"\n",(0,i.jsx)(n.li,{children:"Float64Array"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"errors",children:"Errors"}),"\n",(0,i.jsxs)(n.p,{children:["All functions provided by the ",(0,i.jsx)(n.code,{children:"useExecutorchModule"})," hook are asynchronous and may throw an error. The ",(0,i.jsx)(n.code,{children:"ETError"})," enum includes errors ",(0,i.jsx)(n.a,{href:"https://github.com/pytorch/executorch/blob/main/runtime/core/error.h",children:"defined by the ExecuTorch team"})," and additional errors specified by our library."]}),"\n",(0,i.jsx)(n.h2,{id:"performing-inference",children:"Performing inference"}),"\n",(0,i.jsxs)(n.p,{children:["To run the model with ExecuTorch Bindings, it's essential to specify the shape of the input tensor(s). The ",(0,i.jsx)(n.code,{children:"forward"})," method accepts an ",(0,i.jsx)(n.code,{children:"input"})," (a typed array or an array of typed arrays) and a ",(0,i.jsx)(n.code,{children:"shape"})," (an array of arrays of numbers). Each inner array in ",(0,i.jsx)(n.code,{children:"shape"})," corresponds to the shape of a tensor in the ",(0,i.jsx)(n.code,{children:"input"}),". Outputs from the model, such as classification probabilities, are returned in raw format."]}),"\n",(0,i.jsx)(n.h2,{id:"end-to-end-example",children:"End to end example"}),"\n",(0,i.jsxs)(n.p,{children:["This example demonstrates the integration and usage of the ExecuTorch bindings with a ",(0,i.jsx)(n.a,{href:"/react-native-executorch/docs/0.4.x/computer-vision/useStyleTransfer",children:"style transfer model"}),". Specifically, we'll be using the ",(0,i.jsx)(n.code,{children:"STYLE_TRANSFER_CANDY"})," model, which applies artistic style transfer to an input image."]}),"\n",(0,i.jsx)(n.h3,{id:"importing-the-module-and-loading-the-model",children:"Importing the Module and loading the model"}),"\n",(0,i.jsxs)(n.p,{children:["First, import the necessary functions from the ",(0,i.jsx)(n.code,{children:"react-native-executorch"})," package and initialize the ExecuTorch module with the specified style transfer model."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"import {\n  useExecutorchModule,\n  STYLE_TRANSFER_CANDY,\n} from 'react-native-executorch';\n\n// Initialize the executorch module with the predefined style transfer model.\nconst { isReady, forward } = useExecutorchModule({\n  modelSource: STYLE_TRANSFER_CANDY,\n});\n"})}),"\n",(0,i.jsx)(n.h3,{id:"setting-up-input-parameters",children:"Setting up input parameters"}),"\n",(0,i.jsxs)(n.p,{children:["To prepare the input for the model, define the shape of the input tensor. This shape depends on the model's requirements. For the ",(0,i.jsx)(n.code,{children:"STYLE_TRANSFER_CANDY"})," model, we need a tensor of shape ",(0,i.jsx)(n.code,{children:"[1, 3, 640, 640]"}),", corresponding to a batch size of 1, 3 color channels (RGB), and dimensions of 640x640 pixels."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// This shape is for a single input tensor.\nconst shape = [[1, 3, 640, 640]];\n// Create a Float32Array to hold the pixel data of the image,\n// which should be preprocessed according to the model's specific needs.\nconst input = new Float32Array(1 * 3 * 640 * 640); // fill this array with your image data\n"})}),"\n",(0,i.jsx)(n.h3,{id:"performing-inference-1",children:"Performing inference"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"if (isReady) {\n  try {\n    // Perform the forward operation and receive the stylized image output.\n    const output = await forward(input, shape);\n    console.log('Stylization successful. Output:', output);\n  } catch (error) {\n    // Log any errors that occur during the forward pass.\n    console.error('Error during model execution:', error);\n  }\n}\n"})}),"\n",(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsx)(n.p,{children:"This code assumes that you have handled preprocessing of the input image (scaling, normalization) and postprocessing of the output (interpreting the raw output data) according to the model's requirements. Make sure to adjust these parts depending on your specific data and model outputs."})})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>d});var r=t(96540);const i={},o=r.createContext(i);function s(e){const n=r.useContext(o);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),r.createElement(o.Provider,{value:n},e.children)}}}]);