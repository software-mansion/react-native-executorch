---
title: useObjectDetection
sidebar_position: 1
---

`useObjectDetection` is a hook that lets you seamlessly integrate object detection into your React Native application. Currently, the SSDLite320Large model with MobileNetv3 backbone is supported.

## Reference
```jsx
import { useObjectDetection } from 'react-native-executorch';

function App() {
  const ssdlite = useObjectDetection({
    modelSource: require("./assets/ssdlite320large_mobilenetv3.pte"),
  });

  ...
  for (const detection of await ssdlite.forward("https://url-to-image.jpg")) {
    console.log("Bounding box: ", detection.bbox);
    console.log("Bounding label: ", detection.label);
    console.log("Bounding score: ", detection.score);
  }
  ...
}
```

<details>
<summary>Type definitions</summary>

```typescript
```
</details>

### Arguments

`modelSource`

A String that specifies the path to the model file. You can download the model from our HuggingFace repository.
For SSDLite, you can add it to your assets directory, and use `require()`. If you prefer to download the model
the model in runtime instead of bundling it, you can use the constants that we ship with the library.

### Returns

The hook returns an object with the following properties:


| Field               | Type                               | Description                                                                                                     |
| ------------------- | ---------------------------------- | --------------------------------------------------------------------------------------------------------------- |
| `forward`          | `(input: string) => Promise<Detection[]>` | Function that accepts an image and returns an array of Detection objects                                            |
| `error`             | <code>string &#124; null</code>    | Contains the error message if the model failed to load or failed during generation process                                                          |
| `isGenerating` | `boolean`                          | Indicates whether the model is processing the response                                                  |
| `isReady`      | `boolean`                          | Indicates whether the model has properly loaded and is ready for inference                                                                            |

### Detection object
The detection object is specified as follows:
```typescript
interface Bbox {
  x1: number;
  y1: number;
  x2: number;
  y2: number;
}

interface Detection {
  bbox: Bbox;
  label: keyof typeof CocoLabels;
  score: number;
}
```
The `bbox` property contains information about the bounding box of detected objects. It is represented as two points, one on the left bottom part of the bounding box (x1, y1), the second one as the top right part (x2, y2).
The label property contains the name of the detected object, which is one of `CocoLabels`. The `score` is a confidence score of the detected object.

### Running the model

To run the model, you can use the `forward` method. It accepts one argument, which is the image. It can be either a remote URL,
a local file or base64 encoded image. The function returns an array of `Detection` objects. Each one contains coordinates
of the bounding box, the label of the detected object and confidence score. For more information, please refer to the reference or example.

### End to end example
```tsx
import { useObjectDetection, SSDLITE320LARGE_MOBILENETV3_WEIGHTS } from 'react-native-executorch';

function App() {
  const ssdlite = useObjectDetection({
    modelSource: SSDLITE320LARGE_MOBILENETV3_WEIGHTS, // Can also use require('') as well
  });

  const runModel = async () => {
    const detections = await ssdlite.forward("https://url-to-image.jpg");
    for (const detection of detections) {
      console.log("Bounding box: ", detection.bbox); // [x, y, width, height]
      console.log("Bounding label: ", detection.label);
      console.log("Bounding score: ", detection.score);
    }
  }
}
```

### Benchmarks
TODO